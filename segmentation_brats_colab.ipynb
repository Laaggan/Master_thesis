{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pc0e7NjANKvB"
   },
   "source": [
    "Linus code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab_type": "code",
    "id": "uDKIINKU_HFe",
    "outputId": "3d2a15a1-b629-4339-af7a-e7aac1192cb9",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88.0
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (2.8.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py) (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from h5py) (1.17.3)\n"
     ]
    }
   ],
   "source": [
    "# Install package to be able to save keras weights\n",
    "pip install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab_type": "code",
    "id": "L06f9hdTEJVq",
    "outputId": "a6715b64-fd13-421d-af9b-bd08e59a24f6",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105.0
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nibabel in /usr/local/lib/python3.6/dist-packages (2.3.3)\n",
      "Requirement already satisfied: bz2file in /usr/local/lib/python3.6/dist-packages (from nibabel) (0.98)\n",
      "Requirement already satisfied: numpy>=1.7.1 in /usr/local/lib/python3.6/dist-packages (from nibabel) (1.17.3)\n",
      "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from nibabel) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "pip install nibabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab_type": "code",
    "id": "5et-JeLXj3BG",
    "outputId": "9002d957-1119-4513-a62c-09e945596f70",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at my_drive\n"
     ]
    }
   ],
   "source": [
    "# Mount google drive\n",
    "from google.colab import drive\n",
    "import os\n",
    "drive.mount('my_drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab_type": "code",
    "id": "XN2r9qPvNKvJ",
    "outputId": "b20dffca-d792-4f92-8c31-bb9b1a1335ac",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68.0
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished\n",
      "0.372043776\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import Callback\n",
    "import keras.backend as K\n",
    "import json\n",
    "import psutil\n",
    "import glob\n",
    "import nibabel as nib\n",
    "import os\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.activations import *\n",
    "from keras.optimizers import *\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "\n",
    "def print_memory_use():\n",
    "    '''\n",
    "    Function which prints current python memory usage\n",
    "    '''\n",
    "    process = psutil.Process(os.getpid())\n",
    "    print(process.memory_info().rss/1e9)\n",
    "\n",
    "# What value maps to what class\n",
    "mapping = {\n",
    "    0: \"Null class\",\n",
    "    1: \"Necrotic and non-enhancing tumor core\",\n",
    "    2: \"Edema\",\n",
    "    4: \"GD-enhancing tumor\"\n",
    "}\n",
    "\n",
    "mapping2 = {\n",
    "    0: \"Null class\",\n",
    "    1: \"Tumor\",\n",
    "}\n",
    "\n",
    "def shift_and_scale(x):\n",
    "    assert len(x.shape) == 2, 'The input must be 2 dimensional'\n",
    "    # assert np.std(x) != 0, 'Cant divide by zero'\n",
    "    result = x - np.mean(x)\n",
    "\n",
    "    # This is a really ugly hack\n",
    "    if np.std(x) == 0:\n",
    "        result /= 1\n",
    "    else:\n",
    "        result /= np.std(x)\n",
    "    return result\n",
    "\n",
    "def OHE(Y):\n",
    "    '''\n",
    "    :param Y: A slice containing original BraTS-data with classes {0,1,2,4}\n",
    "    :return: A slice where classes 1 and 4 has been merged and this has been one hot encoded\n",
    "    '''\n",
    "    shape = Y.shape\n",
    "    one_hot_enc = np.zeros(list(shape) + [2])\n",
    "    temp = np.zeros(shape)\n",
    "    temp2 = np.ones(shape)\n",
    "    \n",
    "    ind1 = Y == 1\n",
    "    ind2 = Y == 4\n",
    "    temp[ind1] = 1\n",
    "    temp[ind2] = 1\n",
    "    \n",
    "    temp2 = temp2 - temp\n",
    "    \n",
    "    one_hot_enc[:, :, 0] = temp\n",
    "    one_hot_enc[:, :, 1] = temp2\n",
    "    return one_hot_enc\n",
    "\n",
    "def OHE_uncoding(y, mapping):\n",
    "    result = np.argmax(y, axis=2)\n",
    "    labels = mapping.keys()\n",
    "    temp = np.zeros(result.shape)\n",
    "    for i, label in enumerate(labels):\n",
    "        ind = result == i\n",
    "        temp[ind] = label\n",
    "    return temp\n",
    "\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true[:, 0])\n",
    "    y_pred_f = K.flatten(y_pred[:, 0])\n",
    "    intersection = K.sum(K.abs(y_true_f * y_pred_f), axis=-1)\n",
    "    return (2. * intersection) / (\n",
    "        K.sum(K.square(y_true_f), -1) + K.sum(K.square(y_pred_f), -1) + 1e-8)\n",
    "\n",
    "def IoU(y_true, y_pred):\n",
    "    intersection = K.sum(y_true[:, 0]*y_pred[:, 0])\n",
    "    sum_ = K.sum(K.abs(y_true[:, 0]) + K.abs(y_pred[:, 0]))\n",
    "    return intersection/sum_\n",
    "\n",
    "def reset_config(config, config_path=None, weights_path=None):\n",
    "    new_config = config\n",
    "    if weights_path:\n",
    "        assert type(weights_path) == str, 'The weight path must be a string'\n",
    "        new_config['weights_path'] = weights_path\n",
    "    if config_path:\n",
    "        assert type(config_path) == str, 'The config path must be a string'\n",
    "        new_config['config_path'] = config_path\n",
    "    new_config['history']['training_samples_used'] = 0\n",
    "    new_config['history']['loss'] = []\n",
    "    new_config['history']['val_loss'] = []\n",
    "    new_config['keep_training'] = False\n",
    "\n",
    "class CallbackJSON(Callback):\n",
    "    \"\"\" CallbackJSON descends from Callback\n",
    "        and is used to write the number of training samples that the model has been trained on\n",
    "        and the loss for a epoch\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        \"\"\"Save params in constructor\n",
    "        config: Is a dictionary loaded from a JSON file which is used to keep track of training\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "        self.config_path = config['config_path']\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        \"\"\"\n",
    "        Updates the history of the config dict and saves it to a file\n",
    "        \"\"\"\n",
    "        # How many effective training samples have been used\n",
    "        self.config['history']['training_samples_used'] += self.config['samples_used']\n",
    "        \n",
    "        # Logs the loss of the current epoch\n",
    "        self.config['history']['loss'].append(logs['loss'])\n",
    "        #fixme: add the same code but for \"val_loss\"\n",
    "        self.config['history']['val_loss'].append(logs['val_loss'])\n",
    "        \n",
    "        print_memory_use()\n",
    "        # Save new config file\n",
    "        with open(self.config_path, \"w\") as f:\n",
    "            f.write(json.dumps(self.config))\n",
    "\n",
    "def load_patients(i, j, base_path=\"\", rescale=None):\n",
    "    '''\n",
    "    Function which loads patients from BraTS data\n",
    "    :param i: First patient to be loaded\n",
    "    :param j: From patient i to j load all patients\n",
    "    :param base_path: Specifies where data is\n",
    "    :return: A tuple with data in the first place and labels in the second place.\n",
    "    Data has shape (n,240,240,1) where n is the number of slices from patient i to j who contains tumors\n",
    "    and the labels has has shape (n, 240, 240, 2) which is a pixelwise binary softmax.\n",
    "    '''\n",
    "    assert j >= i, 'j>i has to be true, you have given an invalid range of patients.'\n",
    "    path = base_path + \"MICCAI_BraTS_2019_Data_Training/*/*/*\"\n",
    "    wild_t1ce = path + \"_t1ce.nii.gz\"\n",
    "    wild_gt = path + \"_seg.nii.gz\"\n",
    "\n",
    "    t1ce_paths = glob.glob(wild_t1ce)\n",
    "    gt_paths = glob.glob(wild_gt)\n",
    "\n",
    "    num_patients = j - i\n",
    "    ind = []\n",
    "    #fixme: the list and the set patients should be made into a dictionary\n",
    "    patients = set({})\n",
    "    num_non_empty_slices = 0\n",
    "    labels_of_interest = set([1, 4])\n",
    "\n",
    "    for k in range(i, j):\n",
    "        path_gt = gt_paths[k]\n",
    "        img_gt = nib.load(path_gt)\n",
    "        img_gt = img_gt.get_fdata()\n",
    "        curr_patient = []\n",
    "        for l in range(img_gt.shape[-1]):\n",
    "            labels_in_slice = set(np.unique(img_gt[:, :, l]))\n",
    "            if labels_of_interest.issubset(labels_in_slice):\n",
    "                curr_patient.append(l)\n",
    "                num_non_empty_slices += 1\n",
    "                patients.add(k)\n",
    "        if len(curr_patient) > 0:\n",
    "            ind.append(curr_patient)\n",
    "\n",
    "    image_data = np.zeros((1, 240, 240, num_non_empty_slices))\n",
    "    labels = np.zeros((num_non_empty_slices, 240, 240))\n",
    "    OHE_labels = np.zeros((num_non_empty_slices, 240, 240, 2))\n",
    "    next_ind = 0\n",
    "\n",
    "    for k, y in enumerate(patients):\n",
    "        print('Patient: ' + str(y))\n",
    "        curr_ind = ind[k]\n",
    "\n",
    "        path_t1ce = t1ce_paths[y]\n",
    "        path_gt = gt_paths[y]\n",
    "\n",
    "        img_t1ce = nib.load(path_t1ce)\n",
    "        img_gt = nib.load(path_gt)\n",
    "\n",
    "        img_t1ce = img_t1ce.get_fdata()\n",
    "        img_gt = img_gt.get_fdata()\n",
    "\n",
    "        # This code is necessary when we will use the data from Asgeir\n",
    "        if rescale:\n",
    "            img_gt = zoom(img_gt, rescale, order=0)\n",
    "            img_t1ce = zoom(img_t1ce, rescale, order=0)\n",
    "\n",
    "        temp = 0\n",
    "        for l, x in enumerate(curr_ind):\n",
    "            image_data[0, :, :, next_ind + l] = img_t1ce[:, :, x]\n",
    "            labels[next_ind + l, :, :] = img_gt[:, :, x]\n",
    "            temp += 1\n",
    "        next_ind += temp\n",
    "\n",
    "    for l in range(num_non_empty_slices):\n",
    "        image_data[0, :, :, l] = normalize(image_data[0, :, :, l])\n",
    "        OHE_labels[l, :, :, :] = OHE(labels[l, :, :])\n",
    "\n",
    "    # The last axis will become the first axis\n",
    "    image_data = np.moveaxis(image_data, -1, 0)\n",
    "    image_data = np.moveaxis(image_data, 1, 3)\n",
    "    return (image_data, OHE_labels, patients)\n",
    "\n",
    "def conv_block(input_, num_kernels, kernel_size, act_func, drop_rate):\n",
    "    conv = Conv2D(num_kernels, kernel_size,activation = act_func, padding = 'same', kernel_initializer = 'he_normal')(input_)\n",
    "    conv = Conv2D(num_kernels, kernel_size, activation = act_func, padding = 'same', kernel_initializer = 'he_normal')(conv)\n",
    "    drop = Dropout(drop_rate)(conv)\n",
    "    return conv\n",
    "\n",
    "def conv_block(input_, num_kernels, kernel_size, act_func, drop_rate):\n",
    "    argz = [num_kernels, kernel_size]\n",
    "    kwargz = {'activation':act_func, 'padding':'same', 'kernel_initializer':'he_normal'}\n",
    "    conv = Conv2D(*argz, **kwargz)(input_)\n",
    "    conv = Conv2D(*argz, **kwargz)(conv)\n",
    "    drop = Dropout(drop_rate)(conv)\n",
    "    return conv\n",
    "\n",
    "def conv_block_resnet(input_, num_kernels, kernel_size, act_func, drop_rate, input_size):\n",
    "    argz = [num_kernels, kernel_size]\n",
    "    kwargz = {'activation':act_func, 'padding':'same', 'kernel_initializer':'he_normal'}\n",
    "    conv = Conv2D(*argz, **kwargz)(input_)\n",
    "    conv = Conv2D(*argz, **kwargz)(conv)\n",
    "    conv = Conv2D(input_size[-1], (1,1), activation = 'linear', padding = 'same', kernel_initializer = 'he_normal')(conv)\n",
    "    conv = Dropout(drop_rate)(conv)\n",
    "    merge = Add()([input_, conv])\n",
    "    merge = BatchNormalization()(merge)\n",
    "    merge = Activation(act_func)(merge)\n",
    "    return merge\n",
    "\n",
    "def down_sampling_block(input_, act_func, num_kernels, drop_rate, input_size, res=False):\n",
    "    if res:\n",
    "        skip = conv_block_resnet(input_=input_, num_kernels=num_kernels, kernel_size=(3,3), \n",
    "                                 act_func=act_func, drop_rate=drop_rate, input_size=input_size)\n",
    "    else:\n",
    "        skip = conv_block(input_, num_kernels=num_kernels, kernel_size=(3,3), act_func=act_func, drop_rate=drop_rate)\n",
    "    pool = MaxPooling2D(pool_size = (2, 2))(skip)\n",
    "    return skip, pool\n",
    "\n",
    "def up_sampling_block(input_, skip, act_func, num_kernels, drop_rate, input_size, res=False):\n",
    "    up = UpSampling2D(size = (2, 2))(input_)\n",
    "    merge = concatenate([skip, up], axis = 3)\n",
    "    if res:\n",
    "        conv = conv_block_resnet(up, num_kernels=num_kernels, kernel_size=(3,3), \n",
    "                                 act_func=act_func, drop_rate=drop_rate, input_size=input_size)\n",
    "    else:\n",
    "        conv = conv_block(merge, num_kernels, (3,3), act_func, drop_rate)\n",
    "    return conv\n",
    "\n",
    "def unet_clean(pretrained_weights = None, input_size = (256, 256, 1), num_classes=2, learning_rate=1e-4, act_func='relu', res=False):\n",
    "    # Encoder\n",
    "    inputs = Input(input_size)\n",
    "    skip1, pool1 = down_sampling_block(inputs, act_func, num_kernels=64, drop_rate=0, input_size = input_size, res=res)\n",
    "    skip2, pool2 = down_sampling_block(pool1, act_func, num_kernels=128, drop_rate=0, input_size = input_size, res=res)\n",
    "    skip3, pool3 = down_sampling_block(pool2, act_func, num_kernels=256, drop_rate=0, input_size = input_size, res=res)\n",
    "    skip4, pool4 = down_sampling_block(pool3, act_func, num_kernels=512, drop_rate=0.2, input_size = input_size, res=res)\n",
    "    \n",
    "    #Bottleneck\n",
    "    conv5 = conv_block(pool4, 1024, 3, act_func, drop_rate=0.2)\n",
    "    \n",
    "    # Decoder\n",
    "    conv6 = up_sampling_block(conv5, skip4, act_func, 512, drop_rate = 0.2, input_size = input_size, res=res)\n",
    "    conv7 = up_sampling_block(conv6, skip3, act_func, 256, drop_rate = 0, input_size = input_size, res=res)\n",
    "    conv8 = up_sampling_block(conv7, skip2, act_func, 128, drop_rate = 0, input_size = input_size, res=res)\n",
    "    conv9 = up_sampling_block(conv8, skip1, act_func, 64, drop_rate = 0, input_size = input_size, res=res)\n",
    "    conv9 = Conv2D(num_classes, 1, activation = act_func, padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "\n",
    "    reshape = Reshape((num_classes, input_size[0] * input_size[1]), input_shape = (num_classes, input_size[0], input_size[1]))(conv9)\n",
    "    permute = Permute((2, 1))(reshape)\n",
    "    activation = Softmax(axis=-1)(permute)\n",
    "    \n",
    "    model = Model(input=inputs, output=activation)\n",
    "    model.compile(optimizer=Adam(lr=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    if pretrained_weights:\n",
    "        model.load_weights(pretrained_weights)\n",
    "    return model\n",
    "\n",
    "def unet_depth(pretrained_weights = None, input_size = (256, 256, 1), num_classes=2, learning_rate=1e-4, act_func='relu', res=False, \n",
    "               depth=4, num_kernels = [64, 128, 256, 512]):\n",
    "    assert depth == len(num_kernels), 'Depth and number of kernel sizes must be equal'\n",
    "    \n",
    "    encoder = []\n",
    "    inputs = Input(input_size)\n",
    "    for i in range(depth):\n",
    "        if i == 0:\n",
    "            skip, conv = down_sampling_block(inputs, act_func, num_kernels=num_kernels[i], drop_rate=0, input_size = input_size, res=res)\n",
    "            result = [skip, conv]\n",
    "            encoder.append(result)\n",
    "        else:\n",
    "            skip, conv = down_sampling_block(encoder[i-1][1], act_func, num_kernels=num_kernels[i], drop_rate=0, input_size = input_size, res=res)\n",
    "            result = [skip, conv]\n",
    "            encoder.append(result)\n",
    "\n",
    "    bottleneck = conv_block(encoder[depth - 1][1], 1024, 3, act_func, drop_rate=0.2)\n",
    "\n",
    "    decoder = []\n",
    "    for i in range(depth):\n",
    "        if i == 0:\n",
    "            skip = encoder[depth - 1][0]\n",
    "            decoder.append(up_sampling_block(bottleneck, skip, act_func, num_kernels=num_kernels[depth - i - 1], drop_rate=0, input_size = input_size, res=res))\n",
    "        else:\n",
    "            skip = encoder[depth - i - 1][0]\n",
    "            decoder.append(up_sampling_block(decoder[i - 1], skip, act_func, num_kernels=num_kernels[depth - i - 1], drop_rate=0, input_size = input_size, res=res))\n",
    "            \n",
    "    # prepare for softmax\n",
    "    conv = Conv2D(num_classes, 1, activation = act_func, padding = 'same', kernel_initializer = 'he_normal')(decoder[depth - 1])\n",
    "    reshape = Reshape((num_classes, input_size[0] * input_size[1]), input_shape = (num_classes, input_size[0], input_size[1]))(conv)\n",
    "    permute = Permute((2, 1))(reshape)\n",
    "    activation = Softmax(axis=-1)(permute)\n",
    "    \n",
    "    # Compile model and load pretrained weights\n",
    "    model = Model(input = inputs, output = activation)\n",
    "    model.compile(optimizer = Adam(lr=learning_rate), loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
    "    if (pretrained_weights):\n",
    "        model.load_weights(pretrained_weights)\n",
    "    return model\n",
    "\n",
    "def unet(pretrained_weights=None, input_size=(256, 256, 1), num_classes=1, learning_rate=1e-4, metrics=[dice_coefficient]):\n",
    "    inputs = Input(input_size)\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool4)\n",
    "    conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    up6 = Conv2D(512, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n",
    "        UpSampling2D(size=(2, 2))(drop5))\n",
    "    merge6 = concatenate([drop4, up6], axis=3)\n",
    "    conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge6)\n",
    "    conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv6)\n",
    "\n",
    "    up7 = Conv2D(256, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n",
    "        UpSampling2D(size=(2, 2))(conv6))\n",
    "    merge7 = concatenate([conv3, up7], axis=3)\n",
    "    conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv7)\n",
    "\n",
    "    up8 = Conv2D(128, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n",
    "        UpSampling2D(size=(2, 2))(conv7))\n",
    "    merge8 = concatenate([conv2, up8], axis=3)\n",
    "    conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv8)\n",
    "\n",
    "    up9 = Conv2D(64, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n",
    "        UpSampling2D(size=(2, 2))(conv8))\n",
    "    merge9 = concatenate([conv1, up9], axis=3)\n",
    "    conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
    "    conv9 = Conv2D(num_classes, 1, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
    "\n",
    "    reshape = Reshape((num_classes, input_size[0] * input_size[1]),\n",
    "                      input_shape=(num_classes, input_size[0], input_size[1]))(conv9)\n",
    "    permute = Permute((2, 1))(reshape)\n",
    "    activation = Softmax(axis=-1)(permute)\n",
    "\n",
    "    model = Model(input=inputs, output=activation)\n",
    "    model.compile(optimizer=Adam(lr=learning_rate), loss='categorical_crossentropy', metrics=metrics)\n",
    "    if (pretrained_weights):\n",
    "        model.load_weights(pretrained_weights)\n",
    "    return model\n",
    "\n",
    "print('Finished')\n",
    "print_memory_use()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab_type": "code",
    "id": "9lAteXmGZPqL",
    "outputId": "efc8c5af-fd77-4ccb-f4ea-82090afca1a3",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000.0
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient: 0\n",
      "Patient: 2\n",
      "Patient: 3\n",
      "Patient: 5\n",
      "Patient: 7\n",
      "Patient: 8\n",
      "Patient: 9\n",
      "Patient: 10\n",
      "Patient: 14\n",
      "Patient: 15\n",
      "Patient: 16\n",
      "Patient: 17\n",
      "Patient: 22\n",
      "Patient: 23\n",
      "Patient: 24\n",
      "Patient: 27\n",
      "Patient: 28\n",
      "Patient: 30\n",
      "Patient: 36\n",
      "Patient: 37\n",
      "Patient: 38\n",
      "Patient: 40\n",
      "Patient: 41\n",
      "Patient: 42\n",
      "Patient: 43\n",
      "Patient: 44\n",
      "Patient: 45\n",
      "Patient: 48\n",
      "Patient: 49\n",
      "Patient: 50\n",
      "Patient: 52\n",
      "Patient: 53\n",
      "Patient: 54\n",
      "Patient: 56\n",
      "Patient: 57\n",
      "Patient: 58\n",
      "Patient: 60\n",
      "Patient: 61\n",
      "Patient: 62\n",
      "Patient: 64\n",
      "Patient: 65\n",
      "Patient: 66\n",
      "Patient: 68\n",
      "Patient: 69\n",
      "Patient: 70\n",
      "Patient: 71\n",
      "Patient: 72\n",
      "Patient: 74\n",
      "Patient: 75\n",
      "Patient: 76\n",
      "Patient: 77\n",
      "Patient: 78\n",
      "Patient: 79\n",
      "Patient: 80\n",
      "Patient: 81\n",
      "Patient: 82\n",
      "Patient: 83\n",
      "Patient: 84\n",
      "Patient: 85\n",
      "Patient: 86\n",
      "Patient: 87\n",
      "Patient: 88\n",
      "Patient: 89\n",
      "Patient: 90\n",
      "Patient: 91\n",
      "Patient: 92\n",
      "Patient: 93\n",
      "Patient: 94\n",
      "Patient: 95\n",
      "Patient: 96\n",
      "Patient: 97\n",
      "Patient: 98\n",
      "Patient: 99\n",
      "Patient: 100\n",
      "Patient: 101\n",
      "Patient: 102\n",
      "Patient: 103\n",
      "Patient: 104\n",
      "Patient: 105\n",
      "Patient: 106\n",
      "Patient: 107\n",
      "Patient: 108\n",
      "Patient: 109\n",
      "Patient: 110\n",
      "Patient: 111\n",
      "Patient: 112\n",
      "Patient: 113\n",
      "Patient: 114\n",
      "Patient: 115\n",
      "Patient: 116\n",
      "Patient: 117\n",
      "Patient: 118\n",
      "Patient: 119\n",
      "Patient: 120\n",
      "Patient: 121\n",
      "Patient: 122\n",
      "Patient: 123\n",
      "Patient: 124\n",
      "Patient: 125\n",
      "Patient: 126\n",
      "Patient: 127\n",
      "Patient: 128\n",
      "Patient: 129\n",
      "Patient: 130\n",
      "Patient: 131\n",
      "Patient: 132\n",
      "Patient: 133\n",
      "Patient: 134\n",
      "Patient: 135\n",
      "Patient: 136\n",
      "Patient: 137\n",
      "Patient: 138\n",
      "Patient: 139\n",
      "Patient: 140\n",
      "Patient: 141\n",
      "Patient: 142\n",
      "Patient: 143\n",
      "Patient: 144\n",
      "Patient: 145\n",
      "Patient: 146\n",
      "Patient: 147\n",
      "Patient: 148\n",
      "Patient: 149\n",
      "Patient: 150\n",
      "Patient: 151\n",
      "Patient: 152\n",
      "Patient: 153\n",
      "Patient: 154\n",
      "Patient: 155\n",
      "Patient: 156\n",
      "Patient: 157\n",
      "Patient: 158\n",
      "Patient: 159\n",
      "Patient: 160\n",
      "Patient: 161\n",
      "Patient: 162\n",
      "Patient: 163\n",
      "Patient: 164\n",
      "Patient: 165\n",
      "Patient: 166\n",
      "Patient: 167\n",
      "Patient: 168\n",
      "Patient: 169\n",
      "Patient: 170\n",
      "Patient: 171\n",
      "Patient: 172\n",
      "Patient: 173\n",
      "Patient: 174\n",
      "Patient: 175\n",
      "Patient: 176\n",
      "Patient: 177\n",
      "Patient: 178\n",
      "Patient: 179\n",
      "Patient: 180\n",
      "Patient: 181\n",
      "Patient: 182\n",
      "Patient: 183\n",
      "Patient: 184\n",
      "Patient: 185\n",
      "Patient: 186\n",
      "Patient: 187\n",
      "Patient: 188\n",
      "Patient: 189\n",
      "Patient: 190\n",
      "Patient: 191\n",
      "Patient: 192\n",
      "Patient: 193\n",
      "Patient: 194\n",
      "Patient: 195\n",
      "Patient: 196\n",
      "Patient: 197\n",
      "Patient: 198\n",
      "Patient: 199\n",
      "Patient: 292\n",
      "Patient: 293\n",
      "Patient: 294\n",
      "Patient: 295\n",
      "Patient: 296\n",
      "Patient: 297\n",
      "Patient: 298\n",
      "Patient: 299\n",
      "Patient: 300\n",
      "Patient: 301\n",
      "Patient: 302\n",
      "Patient: 303\n",
      "Patient: 304\n",
      "Patient: 305\n",
      "Patient: 306\n",
      "Patient: 307\n",
      "Patient: 308\n",
      "Patient: 309\n",
      "Patient: 310\n",
      "Patient: 311\n",
      "Patient: 312\n",
      "Patient: 313\n",
      "Patient: 314\n",
      "Patient: 315\n",
      "Patient: 316\n",
      "Patient: 317\n",
      "Patient: 318\n",
      "Patient: 319\n",
      "Patient: 320\n",
      "Patient: 321\n",
      "Patient: 322\n",
      "Patient: 323\n",
      "Patient: 324\n",
      "Patient: 325\n",
      "Patient: 326\n",
      "Patient: 327\n",
      "Patient: 328\n",
      "Patient: 329\n",
      "Patient: 330\n",
      "Patient: 331\n",
      "Patient: 332\n",
      "Patient: 333\n",
      "Finished\n",
      "11.871612928\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set name of who is running the script to determine which path to use\n",
    "name = \"linus\"\n",
    "# Code snippet to fix that colab notebook and local notebook access data\n",
    "# through different paths\n",
    "var = os.uname()\n",
    "run_on_colab = var[0] == \"Linux\"\n",
    "carl_path = \"/content/my_drive/My Drive/Plugg/\"\n",
    "linus_path = \"/content/my_drive/My Drive/\"\n",
    "\n",
    "if name == \"linus\":\n",
    "  path = linus_path\n",
    "else:\n",
    "  path = carl_path\n",
    "\n",
    "if run_on_colab:\n",
    "    base_path = path + \"EXJOBB/\"\n",
    "else:\n",
    "    base_path = ''\n",
    "\n",
    "# Much cleaner loading of patients\n",
    "train_data = load_patients(i=0, j=200, base_path=base_path)\n",
    "val_data = load_patients(i=291, j=334, base_path=base_path)\n",
    "\n",
    "print('Finished')\n",
    "print_memory_use()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SCUKXYxiZPqO"
   },
   "source": [
    "Separate input and labels and validate that the loading of the data has been done correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab_type": "code",
    "id": "PidEBsLpNKvT",
    "outputId": "8486cf49-c508-4b64-ea8e-5c8d595d591b",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 592.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6136, 240, 240, 1)\n",
      "(6136, 240, 240, 2)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATQAAAD8CAYAAAD5TVjyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO29e5BtV33f+fmtvc/pvlcPkCwsNJJA\nElwgwmAeioAyZTvGxIKZQk4lpoRrxvIMGXlq0IwTj1MjylPYw1RqbCexJ66oqMg2FZyKkRlixzcZ\nZRRDSLk8ILjCloUkLHEthJEiwHpYz9vdZ+/1mz/WY6+9z+nuc+/tvufc079P1ak+j33WXud072//\nnmuJqmIYhrEKuEVPwDAMY68wQTMMY2UwQTMMY2UwQTMMY2UwQTMMY2UwQTMMY2XYN0ETketE5EER\nOS4it+zXeQzDMBKyH3VoIlIBDwHvBh4FjgEfUNUH9vxkhmEYkf2y0K4Fjqvqw6q6BdwOXL9P5zIM\nwwCg3qdxLwW+WTx+FHjbdgePZU3XOWefpmIYBsBzPP2Eqr7sVN//I3/jHH3yqXauY7987+adqnrd\nqZ7rVNkvQdsVEbkJuAlgncO8Td61qKkYxoHgM/rpb5zO+598quVLd75irmOrS7520emc61TZL0F7\nDLi8eHxZfC6jqrcBtwGcLxdaQ6lhLDkKePyip7Ej+yVox4AjInIlQchuAH58n85lGMYZQFEmOp/L\nuSj2RdBUtRGRm4E7gQr4uKrevx/nMgzjzHFQLTRU9Q7gjv0a3zCMM4uitEu+3NjCkgKGYZx9eEzQ\nDMNYARRol1zQrJfTMIy58ehct3nYrT1SRH5VRO6Jt4dE5K92G9MsNMMw5kKByR7F0GJ75K0U7ZEi\ncrRsj1TVv18c/z8Bb95tXLPQDMOYC0Vp57zNwcm2R34A+ORug5qFZhjGfCi0exdCm7s9UkReCVwJ\n/MfdBjVBMwxjLkKnwNxcJCJ3F49vi91Bp8INwKdVd6/qNUEzDGNOhBaZ9+AnVPWaHV7ftT2y4Abg\nQ/Oc1ATNMIy5CEmBuQVtN+ZqjxSR1wEXAF+YZ1ATNMMw5iLUoe2NoG3XHikiHwXuVtWj8dAbgNt1\nzpVoTdAMw5gbv3cW2sz2SFX9yODxL5zMmCZohmHMxV5aaPuFCZphGHOhCO2Sl66aoBmGMTd76XLu\nByZohmHMhSJsabXoaeyICZphGHMRCmvN5TQMY0WwpIBhGCuBqtCqWWiGYawI3iw0wzBWgZAUWG7J\nWO7ZGYaxNFhSwDCMlaK1OjTDMFYB6xQwDGOl8JblNAxjFQjN6SZohmGsAIowsdYnwzBWAVWssNYw\njFVBrLDWMIzVQDELzTCMFcKSAoZhrASK2AKPhmGsBmEbu+WWjOW2Hw3DWCLCRsPz3OYaTeQ6EXlQ\nRI6LyC3bHPN+EXlARO4Xkd/ebczlllvDMJYGZe86BUSkAm4F3g08ChwTkaOq+kBxzBHgw8D3qerT\nIvLdu41rFpphGHOzhxbatcBxVX1YVbeA24HrB8f898Ctqvo0gKp+Z7dBTdAMw5gLVcGrm+sGXCQi\ndxe3mwbDXQp8s3j8aHyu5DXAa0Tk/xORu0Tkut3meFoup4g8AjwHtECjqteIyIXA7wBXAI8A708K\naxjG2UtICszd+vSEql5zmqesgSPADwKXAX8oIm9Q1b/a7g17YaH9DVV9UzH5W4DPquoR4LPxsWEY\nZz1hT4F5bnPwGHB58fiy+FzJo8BRVZ2o6teBhwgCty374XJeD3wi3v8E8KP7cA7DMM4wISkgc93m\n4BhwRESuFJExcANwdHDMvyFYZ4jIRQQX9OGdBj1dQVPgP4jIlwsf+WJVfTze/xZw8WmewzCMJaHF\nzXXbDVVtgJuBO4GvAp9S1ftF5KMi8r542J3AkyLyAPA54B+o6pM7jXu6ZRvvVNXHYjr1D0TkzwaT\nVhHRWW+MAngTwDqHT3MahmHsN3vdKaCqdwB3DJ77SHFfgZ+Jt7k4LQtNVR+LP78D/B4hFfttEbkE\nIP6cmWpV1dtU9RpVvWbE2ulMwzCMM4THzXVbFKd8ZhE5R0TOS/eBvwncR/CDb4yH3Qj8/ulO0jCM\nxaMKE+/mui2K03E5LwZ+T0TSOL+tqv+viBwDPiUiHwS+Abz/9KdpGMaiCS7ncpeunrKgqerDwPfO\neP5J4F2nMynDMJaTefs0F4X1chqGMRepbGOZMUEzDGNOVtjlNAzj4GF7ChiGsRKELKdtY2cYxgpg\nS3AbhrFSmMtpGMZKYFlO48Bx8RfO5/Ofv5rzjwvNYWH8jPLCpcJ3veNbnHPdjgslGGcBluU0Vp7m\nh96K22oZP/KXPHmD47Xyn9FDa+jaCICXHl+n+dJ38fyPvQw/EtI/+WZdaM4Jj6stRVrQCsSDtDA5\nV3j5//X5BX4yo0RVaEzQjFVF3vx6qr96nvrrT6B1BXWFjmr8+Yfw66MsXL4WEKgmimtg8yXhoqgm\nwIsaXtsEN1HasSAe6s0gcE/81DtQBy/72BcW90GNjLmcxkpSX3UFujkJQjYe4ddr/LgGJ/iRQ1pF\nK0EroV2v8GNBvCKqtGOotmD96RZfC74OYict+FE4TkUQFaQFaeDpG9/BBZ8wUVskFkMzVhZ/3iG0\ndnB4jB9XaOXwo84dkcajlUMrQVRxE5BWaQ456hMgXqlOtNQK7ZpDfHifm4Tl89p18DWog9GL4f3P\nv//tnPupuxbxcY3IsgvacjvExtKi4zqKWIW68EdenWgYPbdFdaJBFFCQRnETxW15xIe42dpzLfVm\nEC6tJMTVXBAvXwuTcx2+Etq1MK54cI1SbXk2/qtrF/WRDzypDm2PluDeF8xCM04JPfYVqldfiUwa\n/AXnAdCct8bkUB1cy8bjJsHsauuKrZfUbJ4ntIckWlxKu14hXnFbQaxc46ENz29cNGL9Kc/6Uw1a\nB9cTVcbPbOF/4M1svnSEVsLh3/3iAr+Fg4fVoRkri2xOoK6g8Yj3SDNCaqE5VCHe4RpFJbiUk8PC\nxkWCVqCPw+iFIHbVZos0Gqw8BzpyiMLo+SiIItECVKQVpFVGf/kC0hymXavQd3wv8oU/XewXcUBQ\nhWaBizfOw3LPzlha5K2vRw+vh/KMUYU/PMavV/gqCJMfhZia1uFPTDyMXoDRczB+pqF+ocFtefCA\nhgSCr4KrqZVQbbSk3SiqTY+baEwWgI4qUMVttUjr8e980+xJXvuG7V8zTglzOY2VofprR2hfcghf\nO9xWiz9vHSRkNXXUJQXcpgcn4DWUYJzw1C+0tOuO5rCjPtGiTvDjkA11DSAgGjKdtAoakgKuDfE3\nrULpB05ozltDaxcSD1Ewefsbkc0W8cFtBdCJxzlBv+9NoIp83iy502GveznjTuj/FKiA31DVXxy8\n/pPAP6Lbr/Ofqepv7DSmCdoBpjpyFYxHsLmFNC1sbKKtB40px6aBqmLze69Ea4Fnt9Cw5HrIYNbh\np3gFD9WJNrxPo2klAqpUmy2V91QnaqrNOoxFSBgg5KQCGkQtCZJLDoSmoltBKwdVcD3TOaRV8AqV\noM4hBFFzWw3atmhVpeGN00T3SNBEpAJuBd5N2FD4mIgcVdUHBof+jqrePO+4JmgHGNmawIlNaFuo\nKqhrZCQwChlMVME5JudVuEbxdbCoqASF7BIS68vUSRAxQllGkhCVkBXFBVdSXag1qyZNfo9WUShd\nKKxFQ2KBKrwexiPXuEnjwzkLgQWPqISJOUV9EDtpmzDPq19D+8BDZ+bLXVH2MClwLXA8LuWPiNxO\n2KR8KGgnhQnaClNffhmo0jz62NRr1cXfHcRHBMYjdFTHn1WOUWnl0FHF6PmW+rmt7s1NagEIQiaq\nnfkjdBYa5Oel9air8nvSa0n4xMeWKOkuGNf4sCVatPRQYqGtj+6pIoT4Wxg3iCe1C3dE0CiMyT2t\nTNROGdU9rUO7FPhm8fhR4G0zjvvbIvL9wEPA31fVb844JmOCtoLUV10BW5PwQITqZS+DzU3aZ58N\nr7/8Ylgbhyr/tXFoWRJB16pO5DQIBK2n2ghGTxaONrik0oYgvWTRKiyyyoW4WOuDaKmidSy09VEA\ns6up3XFOstUFQdSC9RXP4z1u0naxMx+tMg1ur0SLLrmxooJfc8gY2rUqiqBxagjt/FnOi0Tk7uLx\nbap620me8N8Cn1TVTRH5KeATwA/t9AYTtBVEnSAi6Fa0qtTD2hr1ZZeGMgvngkjUVWeRQWcdeZ9/\nuoni12vatSrUidEJGaoIyXoK7qnGwH04bxA0PCHu5TvLzE1a/FodxkjPu05qshXnNSumxHlpIYR4\noJbOKmyDuynOdZ8jdiy4xockxOtfS3v/g6f/RR9ATiKG9oSqXrPD648BlxePL6ML/sdz6ZPFw98A\nfnm3k5qgrRj1Fa+Apg0Xc9uCOGRtLcTFRnUWNAjlDyoSRCE8A7XrBAMAj0xaXLLMkuglSw6CmMiM\nP3QhnisK4aSFysUugs7Sy2cvhLA3TIyVJSHVygVxakL2U4XcOpWJtXFJrGWzDUVKRbzOODn2uJfz\nGHBERK4kCNkNwI+XB4jIJar6eHz4PuCruw1qgnaWU1/xCpg00LZo06BP/RWMR0HEXnp+dL9cFDMX\nBKwqhKgkBuOpXGwOV5iA22qgadG1uhMIDcKQs42qQbCiWEolwS0sziFNFMQ2CKdEiy8dI5Cb2oEw\nliq0HimSDcnFTeO7jUlPUBUXinSdC9nOSRtcXip0JOjhcSjzaKMrfPd9e/PLWHV0+k/mlIdSbUTk\nZuBOQtnGx1X1fhH5KHC3qh4F/mcReR/QAE8BP7nbuCZoZyHV1a+BSYNMotBsTUKJRSy3kLU19NzD\n6KExMml7IiaqaEsMnGvf0qKozNcYE6sd2grS0AmQc+RlsbwvLLzoFoqgSBaM7Bam2Fzb5itDRbIr\n2QmcC+UXk0nnDg+uJBWCu5uI2df8GZEuGZDEUDyy2U1WnQui/ebXoyMHX/rKqf1CDhB72fqkqncA\ndwye+0hx/8PAh09mTOsUOMuor3wl8sKJIGatRycT8G1wL73C2lqo3l8fhSC8SO+3nAUkWUvSLbhY\nlly4SYtsNchWE56vY8LA0wXt/cDVLF3QshYNunhWIomY912JRtPm94qPru5GE4RRBtag1zBGeX4t\nXo99ofnzR4tRXXfLZR8uxvre/sZT/8UcADQmBea5LQqz0M4S6ldeHgRkYzO6hVWwzCZb4XmAtTXk\nnEPoOKwUi2pniUEveyjeR9dMszsHhKyhp3MdU5yqtOgq6RICIuC0c1dTtlEULUw3aaJweTq30/vO\nohNB6iq4m644V9OGhEIT5kYVhTVZc/hwvBQWXCzp6Il5LsDthBzvEedIeU/34hb619+AHjNLbTv2\nyuXcL8xCOwuoL7s0B/q1adHJBN3YgM3NIGZO4NB6ELPD60VJQxQx6VyxFBjPjz2x1agojI2B82zh\npZtzfRc1ilQeq41ipjrliuYrwXf3g6UYrbJKgnvpuj9JrR26Fv/nRiHKbmzCx3KSXKumvXMA3Xui\nCyqTtrMYizo1nMO9uIV74+tO8ze2uqjKXLdFYRbaElJf+coQ6E/C0DSoxvYeH13LygWLrHJQ111x\nLHSxqkk7nQDw0gX8Gx/qtlTBS1+sfCEasRSirFGDGKtKh8UC29IKDOMQRDQF3SQKnwvBexnFrGOv\nGLe4X5Rf6LgObnDje8dqsujS05UE65NOzHoJCNcJPoN9c1VC7K169ZW0x7++3a/oQBL+Xyx3htgE\nbRnZmoSsZVnWoMHdkmoURGVt3NWTORcEDqZ9ghgsD/EnhVFRzJoSBBBcz8Zna0eUGDtzQRjjBiZ5\nTMdU+UNPzHwIwkMIvmsaJ3UWtOH4PIanE81ijK6WbPv43JTVBiEuVgpf8d30S1UG31ntUBWkaa2r\nYAbLvmKtCdoSUV/xCtjc6rKW2QV0oZ5sPA71ZE5CLMlJLGaVrhC1V+mvfQtGtcsgxmRAep96IeSw\nXBCuaFlp7bL7GEoqomXmB0WwIoB2GUtV0GgN4sMc4vw0FcL6srsgiYz2x42oEqyzVNaRBDC+mGJm\nKcPZczuLc/csySK+1p1EcukKqlRWhNtj2WNoJmjLxOZWyFq2sShWBUZjJFX3r4+7i7MKwpQXpEjp\n9GHWL17sU69FAcrZRueCSElwP4NLGtqVUtBddTAGXfX+FEVtmbYg2vZd2igoWsTapLCgkhhDLK9o\nNZelQDG/4juQMi42LPYdurRD17h0070PvwMAr7jveR3+vj+b/TkPEIrgl3yBRxO0JaC+5OXBktqK\n1hmEzGNVdTGyUbyFF/uBcChiVd3FqkWAPQlIvmgh1IOl1wpKy0iK8o6MFv2QSbhK0Swtnei24rvK\n/t6cBufTLHTSe54mztUV1leytpC+lVpaZ2WyoBDT5PaC9uc0rM3zYcUPcz8DS26gmaAtmurIVehf\nPolOwhI3UlVBuESQ0Sg0kY9HwQWKpQbhQh5YGCmwrwq+6VtwRYVDsGxSZrEfd4tO47Rf4UMGMC2q\nmOeRxpuK26UC3Gj1bDUhjpbcyiLTOhSfTmi6zyWqoQ4uik22xAZjlgKuuJ7FVrqdvbgdUYx927ce\nq84SlhNbNN91LtX3/jXcsy/SfP0bU7/HA4ElBYzdkKbFt90FyqgOQlaHvkutq+7igr7FER+nC7mz\naIJoifgcCyqzhXmcuAoGdRXGKAPvpZXSanZFe5aaI4tPrrrvlVTERITrW2I90YzZzjytts2fSbyP\nY8RasyaKTt1PTZYi2CukdS6IbhK+NOf0Habezpa+xVkKYHzsJm3Y6Wp0wC+ZJTfRltshPgic2Ajx\nMueCe5mEJO5Cnmu/oHAvtbOCNFbVR8stXIzSf08SLl/cTxbaKPZn1gPRjGghaj2Lp3y9PNeg4Txb\nVap9IfbdLdfHDWvkkqVUdgWoZis1xAe77oJszZVTGGZjhyG/fO5o0Q6KjGl9tjJTMW915CoOKlaH\nZuyINtHVlJgAGI+ie1f1rYRwUHcxlxdeO3iucjluBXTuGgSxi61EOqr6Fl9pXQ2D5uU8yuMcqKQs\navGeZBkml7KwJNP7gJ47nNzGnIWUQRytcjFh0q9D68UWU6az7dzhbMFmIYyrjSRrrhwurcpb/iMQ\nQSZt12ngDqYdoID3ixOredj1NyMiHxeR74jIfcVzF4rIH4jI1+LPC+LzIiK/JiLHReReEXnLfk5+\nFWifeDKUYIzqkM0cj8IFOrxo2q7JmsrlTUiAvkXmZEqccuFqeq5yfTdWNa/jD/SD7sMs5tAdLZ7T\n5A4mS3NWfVwpZKUHPLCs8kq4fiBe0E+GuP7nSAIobVvEG7sSlilrNyUhhuI2FPnWh2Ln8r0HDSX8\n05rntiDm+VfzL4DrBs/dAnxWVY8An42PAd4DHIm3m4CP7c00VxtZGyOHDoUEQOX6cbNq4Aal2Jcv\nLsgkJLmBvO9i9jKQSWiG2b+UNS2D9W0hdMPsZFnUWgT2NVli5dhFjE+K9igpBKgnPGVLVGrtKj+z\nK8RyKMxDKzPGz7T4fNn6i5nXPJ9J21lxre+5tiEJ4uMmyu2BbY8qdX6n26LYVdBU9Q8JaxGVXE9Y\nDpf480eL539LA3cBLxWRS/ZqsqtKXoAxuZmlJZYEYlRPB92LmJumm3PdIo5OOostrYlWHAv0La4c\ngxtMMJWDJBofbqlXNFk25fuSu1dmFdPnnfUXP0h0TF0VVfF5En7GVVSOER9n6y8KUy/e2LRh5ZKt\nSdg4uRgrraQrrUeaNq6+G8Q27SR14NA5bwviVGNoFxcrSX4LuDjen7XxwaXA4wwQkZsIVhzrHD7F\naawI2V1MrtrAWiK4jal+rOwQmEVuTm9lSpwU6V3svZ9DUSqznsVrQ0FKNWNl90Caf+/5Yexv1vdQ\nWnZZXGYkOZKwDYV5+H4IolXN+N+dLNP0OVSRja1Y2pF6QX1XA1dkV/VP7t/+c6wsiw34z8NpRzdV\n9ZQ0WVVvU9VrVPWaEWunO42zluq1r+6LV7niRbwoRWNzdVx/TKtqWzEDZltaqV5rSBEvy4+he+/Q\nUkqJzqEFxEDoisJUGcbBZiUXSjEaClbKcg7nkt4zzKymsZPF6qaFdmouqSc2rv4rre+/Xv6TOagx\nNFhZC+3bab3v6FJ+Jz6/68YHRh9dq6EddRfLVJ1X38UsW33KlqHhQo49YUp9j9v8+8prh01Nrot3\nQbTEUqA99ZDC1HunhC2JQCFyvXOUP0vK+Fk5HimeVrx3WLC73Vx64l3G+eL7Usa0Lap7k2s/KyFy\nkFD6VvgScqoW2lHgxnj/RuD3i+d/ImY73w48U7imRkF19WuoXvtq3HMn4ia/VS9DmQLXOqp6q6wC\nYf2uti8AeZ/KfGvDLW4WkoPxaU2wIhiespn5FtcMC+dpe5ZiKVBZ3Nq2e28R08o1aqmeK23eUpID\n8Nrders6FaLWtF2JivddXC2R6vPScSm54HVaMEvXvrQGh+Kb5+HzTc8/B//ON+G+5yAmBmTO22LY\n1UITkU8CP0jYZ+9R4OeBXwQ+JSIfBL4BvD8efgfwXuA48CLw3+7DnFeDSdMF6lPNVrqYkhWW3SHp\nrBDI7mjP+kguVnp+UOmea7qG1kX5XBl/GliKvVai1veFJO0G5fpj91zN7dy+OH5fdAqBGb4v9XJ6\nn7/DPPfyM6SVbV2cny/Ok86ZYmiFW6lOptvKBqgI1QsTZHNrx+NWkiX3tncVNFX9wDYvvWvGsQp8\n6HQnterUV12BarQ8ZLqEotd4ntzF0ksrBKhXNAr9REJ0CXtxn6EYDoPqM+hZg6W7lg+Q2T9nZVB3\nctdS4D4Le+FuZiHrhE9aH79H1xM0aaJVOUwcJLwHle58SZBjHC3LatP255/GT/VoB5ElF7SDWfK8\nQOpXXt6Pz5QXWwpiD62X8md5Px4nyTVr/dTF1ivRGMaXkhtVWjflHEqXMblx6biceCiEo3y+sBjz\na8U5esdDF5TPq89q32rz2n9P7KaQMmEwtFjTfOOmyr1sMnRdB+l7aKMbW1XdXNJwsT5Q6yokDVS7\neNtBQWEvC2tF5DoReTAW4t+yw3F/W0RURHbauBiw1qczTxKJ6BJlaykJyXAT3J4ITf977AlYivXU\nVbGbURHLGpKEI7u02pUmpBU2nOttOze1NE9J3oi4EylhxvFD8RmKXile5ecquwKSNTWw/KSJe4MO\n68TKbOWsz5E/dyHGddXF/IrvUFpPO65n19OtOHv1kUWkAm4F3k0o7zomIkdV9YHBcecBPw18cZ5x\nTdDOEPXll2UrQVNVP11QflgTlZmZ/aOrqM/vdb3yhSBCYYUKSZX1QNrpKBxUxJjy2N2mvhnn+kWs\n6b3D43KMqxOiZO3NXGYo7Y0g0l/vLJEa09PY6fuI4qsjCZ9lIDr5+00JgWLFj97n9sV5hhlQF4Pb\nM8o01An6J/cvu/e1P+xdlvNa4LiqPgwgIrcTCvMfGBz3fwC/BPyDeQY1l/NMETsBNLbr5Mr+aJnp\n8IIts5Yxq9nLJEKuS+uWCIqWX7K20nEp85cu8ORiwbR1lCgzmdCvwyrd4mFLkp++zKfELI8zEJGp\nN0rn0tbTFteslXhTN0RunRqec9ZnLTOo5bHpuy3bz0QOnqtZIDrfjZBEvLu43TQYarsi/O5coRf8\nclX9f+ad38H9zZxhNMVwKtdbvyw0dEdBKpfogamFEjM5FlRcpNndo8tCljGkXjyKnmWnqa1qWB+W\n3l9X/fcPM6HDcVM8rGwzKt3ZRFkHlj5PIn3moUCW50xWXWlFJXFP8bBZ8cN8zkKIi02Mp84lEj5c\nWoXjgK62cZJFs0+o6q4xr+0QEQf8CvCTJ/M+E7QzQPXaV2fxmdozM8WvkpiVJRHZwtL+Benb6WPK\nXcRz87nvhCdvdqLF0j7xAq0EJW7mO8tSawuLLmUR08og0AnLLEHszbuwgGbF4dLcGAjZwI3NP0sx\nHIpr+geykwgPs67DrGz5fDpH5fCHRhxM5g/4z8FuRfjnAd8D/KcYAnk5cFRE3qeqd283qAnamUAV\nUm2VJ4hYsc9lb+NbmC4uVQ3iUVos+eInimA/YK6jCl0bdStKQGioHhHO2Xh0JLnYdurCL7N8TdvF\n/1LMKh6vLuytmTOhaW4MxkvzhGmLbFZHQCJbodoXmt7aatJv60rj9/YhGFiIpbiV2du6itnP4nzF\nObWq0Lvv48Cyd4HDY8AREbmSIGQ3AD+eT6P6DHBReiwi/wn42Z3EDEzQzgwpWJ2WqW5Sq1G88JOY\nTRrEaxcHSoIVL14dDS7IKFQytHg0boTitFe5H85YBTFVRTYHF3yiks6agyik4XkpLMGwskfKNMb4\nXXKfSzc0FbG23RZyvV2d4ucS8XmLvWzhJXFMwphEKYlVPrcrSj3iHMsFHUXCfqdSHFtuEiMSvvty\nscxigcz2q187ld/86jGrH/gUUNVGRG4G7iRs9/xxVb1fRD4K3K2qR09lXBO0M0D74HGqI1eFC7Vy\n00vPFMH2tMF4shpCJ4H0rSgPpD0wU+kHFKUacdhhyYH3XfYzBdyBtE1dru9K5Qnie3PpuanJimti\n7VuK2fmqOzYJuReI+3kmeivSVoVAQlgBty0KWFWD2DgJc6/jRjJlnK/YHyGNlTeESYJdNqrPcK21\nqFfLvbHO4e8ZJt4OKMpeupyo6h2E7qLyuY9sc+wPzjOmCdoZQk5shvqwtTFSbJDbc6NK6yO+JrGq\nPe1ulIP3SSxiHE41uJRhuR4fraIUKyMIHf2K+jCxIgYlxdplyaJstZ98SDFA7QQ1v165vlBEsZEk\nRMlSLBeA9JrFOAmQrtXoWoVs0q16AYgHxYN2/xQkBf8H7moWz2zl0u8VTdnKMs5XbBaj4xo99pWT\n/0WvOLJ3Lue+cEDTNWeW+pWXF1bYIC5TNm7PyrBFASs34U3kpEJx/NSqG5BdPq1dl5TIg3Tj5i3h\nZrkV2QWc3V2AanAd85purt88nt4/a6mfZDnG5vVcjuG66nwd1Z0r3vrcEB/ePwjgJ9HvNbNr//tN\nopYWBWjbbtxJG3Zpf+vrZ3wRBxyd87YgzELbZ+qrrkDXx8jGVnCZykLPnGUcFHYOdjrKm4vkpYAK\nUSosrV69V5m9KwPggFb0CvUfxzwAACAASURBVCSzNZNiXWV8S6SLaSVrL513ELvLe3YO5pVLLNJz\nyQ1M4psyqen4SYMMhHrqOyqPT99lOrZMqqTHw6xm6pDI41ed26zB3XWth6uuoHn4kanfq7GcmKDt\nM7o+7uIzMIiD0bXwJPcy4dg2XjG1dlmMqeF08Li4TyFa0NXAUTyOsa6p86U9Mqfq2YoAehIl1xfP\ncFzxnmEN1zAjCqF9aTJILpSu4XD84Xip+XxYopEst+R6p+bzWLyrVZWX3YYYv3QSym5UaR/68+3P\ne0BYdpfTBG2/UQ3L3JRWUnnRi3RLRJfiUByfLaiipz2LUcoiejpXLV+8xYWf3K5iB3ZJ50+Z0XhY\nbynu5K4Sg+z4vks6dD2T5VO+XlprZRvWLIuyZ8UVVlmiPK60ttL3OqxXK+8PBQ6iyw84163iVc0+\nr3vj62jOX8f90T0cSJS9bH3aF0zQ9puihgvoWxflxr3FuvWzlvfpPVdczKIa9glI5+pRuLD5qRku\nW1mEOmt/gFrAJQuuClZcbHzvlXfA7CV7Zqznny3SmFkta8l02FFQLiuUPkM7Q8Ty+d20CJYCOLyf\nxxx0FxQJCVSRE57aub2qXDg7MQvtYCNNm+u1eq5PIrlS5WuOzhqLgiHlhQZx38noolF1wfrhRZss\ns0RyyaCrtWrIze1pKSIpRETLGFtBSEpUXdZ2xppsPct0RqlEL0uaXORBo31vUcbyvem1cpu71PuZ\n2pSGcyn/UZTf1/A7gy7rnL7DtsU9+yLy2lfTPnicg8iyu5yW5dxvmrZfwJmXoh78ZQzW60rLXuf3\nb02C61rGrXKlve9bZ96HcoZ0zhQ7mpWhTK/FzUHyOUrrJI0zcIVxhBKHeEsu4jATu+3uVCkTmgXL\nFeImXWP4cKntVCJSLvkzPCaNV2z11/scZZJApO/eep1+T1wnTSsHbUt95StnfqaVR+e8LQiz0PaZ\n5puPArGfM12EqSYrWhQhGN0JkGxO8i7dubhUBNpJOH5Ud+t9pQA4IFuT8Fz5WmFx5BVYYee4ksQl\neDRZbVWXaYXpTYmjMGgFSCyOTW5w0R2QrdRYT6eVoK7qHkeLL32GfpJk4DZHoexZkqmYFnJNXmfx\nKrpWh0xsW1izpbgl8Stq7aaWG0/Fv4B74+vw9/7Z9C99lVlyC80E7UzRtjOsjChEpdU0aUK8ZrjE\ndRHXEWn7rmMu64gXWxlzStZaGacrrbsUNyozlKpxU91YnV+mPlOZBUwnMWYF+R0h9laWhJQuNQQr\nr6XzF5KODQPzxTlTvZ3iimzuDEprcW0ELtSYdVnXGLuL/2B0VPUXbpwVoxMJ/2jaJb+695hiaaCl\nxQTtDCGTJlyExe7lEDOYKQsK3QXrCKJWumtp0cGS5DKm4Hopfj7s+N1zeyEct1Nk2yvg43idZZST\nBY6u3aoSpKVfr1Z8jl5bVbTOcHQdCZ5+uUlpiJWfJc0hPU+X1S0TGOVO7vk4CKvnbk76YpkzvkX5\nBoMETLltYAoVVEUZzkHDspwGQPONsJZddeSqsHJGaVWk5aWLoHTqXZTyCi96QDXGjHobeUjRj9i0\nwYqINWCaVqIVgbZFVemtTFuus5+ER0KBqUJoVypLPmaITc9S2w43OC59JKfTx8GU8Jb/CHKnRKuz\nuyPSexCQKq5qor34W3Zby7ggQSSzeMZzCHSdHnVFe/+D23/OFcUsNKOHvLgRxCStJTZpwu5FkN1M\nrVwOsmvZ9wndhRdXTVVXxNiKNddk0nT7YEbxyuvvp9hd68PFnOJJw92dkriNR9m9FRFoY9iully6\nkcVxlvtZ/kwWWWkBla5rbmeKw6n2rdmSQa1c71yJwurTouQk/z5anbl5c7BCXYi5NYV7KhK+14Nq\noZmgGSXNY/8Z6FqieoH4fIG6Xj3a1IYnLl2cAuO6HzyHIGDRzdSpC3zGX6Rq55KW2b5hvVYbBbKu\ngrU4DKyn44Y7VxXTS8sn5c+cGunT68VnnHpfHi+cN6wqUi7FRO/7GrqwueA3WXTOockdTg388XPn\nJEiZGCi/i1nf46pjMTRjW05sBCtrPIIXN8JzSQjqKjSRi4QseLTWfNVZREEAQ9xKG3qiJpO2y5I6\nF0QjrxMWL9ThBZkEo9xdKVllKXsaxSrv96kuZjYHyY5BrVevzWqQORTICYLc6TWIo83cYKV0zwef\nQbLLLF1CYvC6eolR7jhGfE4rCXGi2DI2tT5bEuyDigmaMQudhJ23dS30euZlrUc1/tAoCJrXXE+m\nQm5u78WvGh9WhygFbXPSTwLkF1I2tMvcTVlw8eLuCVNZkzYsnyj7P2e5m/TjUCn+1BOonEAoyj0o\nrLJZiYZZzHA7e10PkoL+TIkchH8K2f3MvbZhefJUfjKzYPcAIX73YxaJCdoi2dgMF9x4lOvNtBL8\nqELHLl5EXSLAbbV5lVpQXNt2K1yUblAaK8bIpHRn82DSVdenx9DF2lJ8LcXmmsFf8rAOrfyZSBd+\n/Agz97EsXdv8OQbHpOdT4kOkX+pSiG2ZGU3nSzVvQLfPaEnp2rb9pv1yPlpVQW7Lej5jqTjAtvNi\naZ94MtzxfatDJi3ViQmyFa6idr1i66Ujtl4yytaTeI/bnCAntkIHQbLOysp66MoQZsR8xLkgWOXO\n53lyLahHY3Z02IVQ7lSe3bt0G9aiFQKjEoqIp6yz+FOarvE9uallp0HeLWu4DtoMEcvnk36ngqQ6\nuDTX8tjkTmeB7N6T35e+ogPa+mSdAsa2NN/6NhBKObTcts173FYTsp113MMz/qZkq+nWFivjOYW1\npIfWgmDFGjXZ3Iqr2nbCpr7tquyhe94xteu4bk1CVjZtnJI2Hq76IjJVN1bUw+UK/OTWebp+1F4l\nPsHSGmQ703m0EqSJn32wJWCOkaV5l7Vug+xqcB8JMcAocNnlTOcbFM6G1XsdemjGGksHAUsKGPOQ\n42SxhEI2m3ABroE0nvpEGy7OWW5O6faV1lBchw1Aqgo2t5C2RYe7iM9wOcNw2j1O5y5X2y02EJnK\nhhbzzAW3yVWM+xDkuaex87hFsB76RbdA2nchWWmlJZficPn4ogQjvbe3wknrQequJzV1HbTTll7a\nbnAocgeOJf/45nIuA5OiFSeWR0jbIpvB/ayf26J+bhKEoBSuYewMOkGrHX5c49frIG7Ohf7IGFPr\n6tK2j/LmY+q610Quw/02E2U9mKSG9e65XklFUWCrxXum+kSZcdyw7iyNV743/WVnMR78qYvEhnb6\n4wzIpTO1C61TB509dDlF5DoReVBEjovILTNe/x9E5Csico+I/JGIXL3bmCZoS0DzzUf7fZmxfEPa\nFvf8JtXzm1QvbOI2J52LVlexHsx1Fle0nLROriGkQtvhqhM5u5k2G0nW03ZWYLmMdZpn1QXhkwWp\nLriB2aIsuyGauDxRsSpHKWZlHKt3buiXfUA3fhKrXlmIdjVoccxe3C7ON++BAH0LML2e4mnxd+Nj\n0/qBa0iPCCHLOc9t17FEKuBW4D3A1cAHZgjWb6vqG1T1TcAvE3ZS3xFzOZeE1BoFUL3mVZ3l1bbR\nYutcO62qzkpJblCRLUwXaqrrkrJINAXlmyY/rxRimopWod8eVe40NdgKrmdhlf8iUzC9zDZGaycs\nJNklG0J70iCwXwpbLVNZ1F62U6RIjvTnJ8V3M2X9ed/vJhDp9jNwIc5G63EbMaZ5kLObextDuxY4\nrqoPA4jI7cD1QN4zUFWfLY4/hzlsPxO0ZSVt1pFWvGiLUoHS5YLprKJz+FHKCMYYU12F7oF4XK+R\nHPIGu70aN6+E9XAn/URBFXZh6raKK1zCYXV/jo0NPp+ja3ROlftFhrHXJZEHHKzam+JepdBF63Aq\n1jWsn2u1J3Rl/VtvvslC25rghitxHET27uNfCnyzePwo8LbhQSLyIeBngDHwQ7sNai7nEiJ5Ozcf\nxEykWwIolTdEq0xa7RW+JncJDQkFaXywYlJXQnI9q6ovirHrIAwSLZuYBdW0flgSgMrlhR2zW5fu\np1vvAw1cyDJgvxOxREWKn2VxbYhrDbbOg85iTZ+lFMYZVuBUWUf8KRpboIqxD2JDeo/5Y2gXicjd\nxe2mUzqd6q2q+irgfwX+t92ONwttGWnbsKx2IgmZ11BW0cYNTjRaWW5wQXpFXCzEVc2rTOiohroK\nrUwpllVulpLOBSERAAjF0kbOhf0xncsWjlYpMSH9zVFcsO26pYU0l2LkuFRy9cr3lZ9j5nej2f2U\n3DLVubpSVvIXY0jbBlcc4lwH2VMfXeJs/RbC1nr82rgrAznAnITL+YSqXrPD648BlxePL4vPbcft\nwMd2O6lZaEtIGU/LCz2WLlNpLcFUbEi8dqtgpBVas1CFjXtJq2yk90e0tGxSc3s6d7Ly0rF13ME8\nxbJKN69MFsTxtKpysL0M2k/FtSAnCHJSoEwWpM/e+FCXB9nqKxMLmqy48rsTCfVwZZGuA+ouGdAT\n960JOqrxh0fol++f+fs6UOxdlvMYcERErhSRMXADcLQ8QESOFA//S+Bruw26q6CJyMdF5Dsicl/x\n3C+IyGMxnXqPiLy3eO3DMQ37oIj8yBwfzJhB8/AjQXDatoujlfjC1SytGVVkowk7f6dGdugslihQ\nOh6UIBQXvaqiTdPF1LyH8SjvXC6qQQBi8W4Wn0FCAMCPY53XMKZVO3RUdeJTSU+wsouZHqcEw7Ae\nL4t4yqAyo2Qjfr7Czc2i2nO7o4XXFP8ARPDnH4IvfYUDj+5dllNVG+Bm4E7gq8CnVPV+EfmoiLwv\nHnaziNwvIvcQ4mg37jbuPC7nvwD+GfBbg+d/VVX/cflETLveALwe+C+Az4jIa1R1Rqe0sStJfOKe\nnTrc0xL6LTwp66lNd1wd+kLlxFYnboCes468uBGSDUU8TZzrW4POhTq2tCBiUQibm9ihWM1W0cqF\nP+xJS9WE+JuOqs61rIu12YpC2CSOkj5fWvlj4D6m53UUViPJCQDvkYbO8vNkoQ2raBTfVSqm1fgd\nlsW8tQsrmKjiX3IYPWZiltnDnIiq3gHcMXjuI8X9nz7ZMXe10FT1D4Gn5hzveuB2Vd1U1a8Dxwnp\nWeMU0I3NvAAk0L+whzGmYTlBdEt1VNEeHocG+HIT3sZ365qVge8yWRBX/2BUZ9cyWzXJpZTB8j4+\nusmxPKNcnDE30kMnzoW7mdd6S895+pX9O5Hmn/o0y++kV6ZRvFY+36ZYo48JmRB/NDHrk/YV2O22\nKE4nhnaziNwbXdIL4nOzUrGXnsY5DjZbE/T559HnXkBObCJNGzKgpUVWuqKFS5lfT9m6Q6NQ6V51\nRbtZzIC8o3lqbh/V6Di8R2sXrJZxHX5WXVFsr2asXEAxz4+ieLXIlg7nXVb6J4sqvjdvkZfGTJnJ\nUpSGtWulyBZlGFl828Hx8Tg5sRWs2aalfeChk/yFHQD2Loa2L5yqoH0MeBXwJuBx4J+c7AAiclNK\n6U7YPMVprDjjEaytgXp0YwOSxTbcIV2ks6aSFZfErlVksw0J0VHVHeuDa5g7DeIquclK07rqW1De\n5/03UylIWWeW419VFLayhAKyKKUspERXNM8/ki23aAmmWFfY8q4L9k/1gCYXNYmjJ2diZdKGW8oW\nlzVohZhqFWr1pGxFMzrmFbMFfnWnVLahqt9O90Xk14F/Fx/OnYpV1duA2wDOlwvtr2cGcmg9XLQb\nm+jWVnBB1cPaGrK+lssoylYeiYID5FVvw85SMyK18f253q14fsr680VJRFEIu60bXLqRifx6mGNu\nlxKQiUJFiL81XUIgNaH3MpVlYXHySNM+njmuVwhpVSGbyZ0kdACU7ugMgW2Pf33nX84BRFisOzkP\npyRoInKJqj4eH/4tIGVAjwK/LSK/QkgKHAG+dNqzPKA0j/xF73F1wQWhyPXFE6HWbDzqAvNti4yD\ne9hccJjqmY2e+yWF2xUGSxX2rivVSC5nRGN3QFiGWjsXsy6Oic+J96Fqnxjcz+1UBDGcFHuCStyU\nOBLiLoq2IM5nazC0R2lxXBSpYkWO3tplZXwvCppfH6G1UDcb/URKWjo8Wmx5x3jve2UzRp+zXtBE\n5JPADxIqfx8Ffh74QRF5E+Gv5hHgpwBi2vVThH6sBviQZTj3Djn/3LBs9+YWNHF7uRgLE4ATm2EP\ngarCvbiRrRVdH8f+zihOZSW9E3BpsbX+7uNl/Ku3OUvp6vlp66ncJzNYetptLDyMeyWrKb5XykUb\n65DF7Lm1VXHu4hzSdEkQPGG18aKftTeX9FlT/Vyx+q2J2S6c7YKmqh+Y8fRv7nD8PwT+4elMyphN\nr4H94u8OcbBkHcWaNVpPNZkE0XOCjKIV18RsZR0ucoHOLaz7pRGpUby3F0BEXdj7M7uE5dpmKYtZ\n0Q/Si6Bjma5FK5MWvXqwrj9ThW7pogrS0uGlpZAXfUyrlKjPrVGu8bAVBbGqpvfzLHtPD+JOTifL\nkn9F1vp0tnL+uV3Gs2lD/Vhdo1udmBE3CUYVqWOV/3gUatPKAtXiZ2/9LydBOCq6i79crDUtHz5j\nfX9pNWZD6dZPK2JfKWYnnuB+pv7OsuMrNplrWjIprceWTiUEYSpFKcUP02q6kzYmFeIKJclSLIt3\nvdJ+7eFT/EUcIBZckjEPJmhnKVMX4LVvQFqPe/YEcmIzWCRshOWzJ00QkM0aWVsLS3SvjfHjqotx\nFeuoaXTfRIPV5ddrxPlgwbho3hWiImnZoTLzSLSYnMRVaMt6M3oCNXQF089QZBusMU1WWblUUt7x\nvBPTnAFNpMJaAZn4LgEA+PsO5rpmp4UJmnFG+NJXUDoDJFG/8vIgDic2gou6uRmSCk5wF740tDRV\ngo6DOyqtomtVKOkAGDnciSasfFuHhneJmcmEVoLGZva8Mct6eChtjGslnfJdciHsmRCek8bjR/1u\nBGl9XlQxdCJEQSWIodYOXzncZgM+LmSZ5pQtwFC24SYt/t4/W/brcemxbeyMhdJ845tUR65C2jFM\nJsH6AnRjE3n6GeT886By2UUE0PUROkqKFX5WL27h1+pg1UnnzoWuABBinCq6qqnQ1tcON/FZAFMb\nF20YWiuHurQOWzxldCPVSRCk1GyvGjdedogLr7eHqmhxeVQkxMwi6uL577rXhGyPMJfTWDwpS9g0\n0DQhKzoek1aTaB+dLhUsK663fvitVJseP3L4cRAk1ygubpqSRWfikc1gDVEJzfnrtOdU3Qa9kBee\nBNDYEeAmiou1cBqFLVhyLjzfKozSmnCACz2Yflzhawl7mDZRjCuBu+4FYt3Ufn2nB5EFF83Ogwna\nQcC5IGRNE+oZXIUcGgPQzBCzqbe3ih87mkMVW+c5xs95Rs9t5qJYILuobqMJ663VVe7pdJst7sQk\nuJXrNe25YyaHa7QS2jWh3vBwIgpc7br4HdA6h3OKHzncluA221AILIIfO/xIgtvZtrg/umd/vj+j\nwwTNWDTtQ39+Wu+vPvfHQPhjWQee/cDbWXsqBto1WVPg1yraQzV64aHwXBVFp3ZxA5bQhuVGLbIe\nEhLNIcfknJr6RMiEtiNwLbhJSAL4CuoNxdeCW3O49SqWYAhrdxw7/S/HmJuV7RQwDjbVRGkO17hG\nka0WaeImIodGNOeOaA7HnaRaRauw+7uOHNKE4H/95PMcenYDvzaifnGN5nBFc8hx4gKhOUdwW7D2\njM/WQLqI2kpY/7fWeLJIlr1WzwTNOGlGz7U051bUL3oQmJw3ot5o8VVaBVaZnFvx4kWhAHf9KYdG\nSwtgvRKqjQZpPONvPce4aWkvOIdm7RxefHloixIvvOxjX1jkxzSGWAzNWEXS8kF+JKg4mnMqmsMV\nvob6RMhIBpcxuIZb50M7EkYvKPWm8vwr1lEHbgLjZ1tGz02on93gwnueZvzCSzj0b8wKW1bM5TRW\njsm5FerAjyrGz7ZUGyFDWW2G7Ke6kLlcf1pp1kKwnxG0a1BNwhjtWJgcDmNsXlAxfnbM+r/7Eods\n2f7lxgTNWDXO/dRdPPl334EfQTuqoqUG6894dEvZfIlj8wKHHxGFD7ZeqvhaedXP3rXo6RungVlo\nxkpy4mWCH8GLLw+pTrcpnPjuinYNpIXJecpVt1gMbOUwQTNWkcv+z89PPfe/P/xlfv6qty5gNsYZ\nQfe29UlErgP+KWFJgt9Q1V8cvP4zwN8lLEX2l8B/p6rf2GlM25fT2DNMzFabVIe2F5ukiEgF3Aq8\nB7ga+EDcNa7kT4BrVPWNwKeBX95tXBM0wzDmp9yLYafb7lwLHFfVh1V1i7Az+vX9U+nnVPXF+PAu\nwpL+O2KCZhjG3OzhNnYnu0PcB4F/v9ugFkMzDGM+Tq6w9iIRubt4fFvcGOmkEZH/GrgG+IHdjjVB\nMwxjbk4iKfCEql6zw+tz7RAnIj8M/BzwA6q6636XJmiGYczNHmY5jwFHRORKgpDdAPx471wibwb+\nOXCdqn5nnkFN0AzDmA9l3oD/7kOpNiJyM3AnoWzj43HXuI8Cd6vqUeAfAecC/7eERUX/QlXft9O4\nJmiGYczNXnYKqOodwB2D5z5S3P/hkx3TBM0wjPmxTgHDMFYBW+DRMIzVIe4fscyYoBmGMT/LrWcm\naIZhzI+5nIZhrAZKt9v9kmKCZhjG/Cy3npmgGYYxP+ZyGoaxMliW0zCM1cC2sTMMY1UIhbXLrWgm\naIZhzM8e7imwH5igGYYxN2ahGYaxGpwFMbRd9xQQkctF5HMi8oCI3C8iPx2fv1BE/kBEvhZ/XhCf\nFxH5NRE5LiL3ishb9vtDGIZxJgi9nPPcFsU8m6Q0wP+iqlcDbwc+FLebugX4rKoeAT4bH0PYlupI\nvN0EfGzPZ20YxmLYu12f9oVdBU1VH1fVP473nwO+Stid5XrgE/GwTwA/Gu9fD/yWBu4CXioil+z5\nzA3DOLPEjYbnuS2Kk9rGTkSuAN4MfBG4WFUfjy99C7g43j/Z7akMwzhbWHILbe6kgIicC/xr4O+p\n6rNxjW8AVFVFTq4pQkRuIrikrHP4ZN5qGMaiWPKkwFyCJiIjgpj9K1X93fj0t0XkElV9PLqUaVeW\nubaninv03QZwvly45F+TYRgA4pe7EG2eLKcAvwl8VVV/pXjpKHBjvH8j8PvF8z8Rs51vB54pXFPD\nMM5WlFBYO89tQcwTQ/s+4L8BfkhE7om39wK/CLxbRL4G/HB8DGEXl4eB48CvA//j3k/bMIwzjaCI\nznebazyR60TkwVjidcuM179fRP5YRBoR+TvzjLmry6mqf0Ro45rFu2Ycr8CH5jm5YRhnGXsU8BeR\nCrgVeDchcXhMRI6q6gPFYX8B/CTws/OOa50ChmHMz95lMK8FjqvqwwAicjuh5CsLmqo+El+b24k9\nqbINwzAOMCcXQ7tIRO4ubjcNRtuX8i6z0AzDmJuTyHI+oarX7OdcZmGCZhjGnOxp0exc5V0ni7mc\nhmHMh7KXnQLHgCMicqWIjIEbCCVfp4UJmmEY87NHdWiq2gA3A3cS+sM/par3i8hHReR9ACLy10Xk\nUeDHgH8uIvfvNq65nIZhzM1eLvCoqncQ6lbL5z5S3D9GcEXnxgTNMIz5sRVrDcNYCVShXe5eThM0\nwzDmxyw0wzBWBhM0wzBWAgVs53TDMFYDBbUYmmEYq4BiSQHDMFYIi6EZhrEymKAZhrEaLHZHp3kw\nQTMMYz4UWPJNUkzQDMOYH7PQDMNYDaz1yTCMVUFBrQ7NMIyVwToFDMNYGSyGZhjGSqBqWU7DMFYI\ns9AMw1gNFG3bRU9iR0zQDMOYj7Ng+SDb9ckwjPlRP99tDkTkOhF5UESOi8gtM15fE5Hfia9/UUSu\n2G1MEzTDMOZCAfU61203RKQCbgXeA1wNfEBErh4c9kHgaVV9NfCrwC/tNq4JmmEY86G6lxbatcBx\nVX1YVbeA24HrB8dcD3wi3v808C4RkZ0GtRiaYRhzs4dJgUuBbxaPHwXett0xqtqIyDPAdwFPbDfo\nUgjaczz9xGf00y+ww0SXlIuwOZ8pzsZ5L9ucX3k6b36Op+/8jH76ojkPXxeRu4vHt6nqbadz/nlY\nCkFT1ZeJyN2qes2i53Iy2JzPHGfjvM/GOe+Eql63h8M9BlxePL4sPjfrmEdFpAZeAjy506AWQzMM\nYxEcA46IyJUiMgZuAI4OjjkK3Bjv/x3gP6ruXNm7FBaaYRgHixgTuxm4E6iAj6vq/SLyUeBuVT0K\n/CbwL0XkOPAUQfR2ZJkEbd/9633A5nzmOBvnfTbO+YyhqncAdwye+0hxfwP4sZMZU3ax4AzDMM4a\nLIZmGMbKsHBB2639YVkQkUdE5Csick9KR4vIhSLyByLytfjzgiWY58dF5Dsicl/x3Mx5SuDX4nd/\nr4i8ZYnm/Asi8lj8vu8RkfcWr304zvlBEfmRBc35chH5nIg8ICL3i8hPx+eX+rteeVR1YTdCMPDP\ngauAMfCnwNWLnNMOc30EuGjw3C8Dt8T7twC/tATz/H7gLcB9u80TeC/w7wEB3g58cYnm/AvAz844\n9ur4d7IGXBn/fqoFzPkS4C3x/nnAQ3FuS/1dr/pt0RbaPO0Py0zZmvEJ4EcXOBcAVPUPCRmhku3m\neT3wWxq4C3ipiFxyZmbasc2ct+N64HZV3VTVrwPHCX9HZxRVfVxV/zjefw74KqGyfam/61Vn0YI2\nq/3h0gXNZTcU+A8i8mURuSk+d7GqPh7vfwu4eDFT25Xt5rns3//N0T37eOHOL92c4yoQbwa+yNn7\nXa8Eixa0s4l3qupbCKsDfEhEvr98UYNfsfQp47NlnsDHgFcBbwIeB/7JYqczGxE5F/jXwN9T1WfL\n186i73plWLSgzdP+sBSo6mPx53eA3yO4Od9ObkP8+Z3FzXBHtpvn0n7/qvptVW017Jv263Ru5dLM\nWURGBDH7V6r6u/Hps+67XiUWLWjztD8sHBE5R0TOS/eBvwncR78140bg9xczw13Zbp5HgZ+IGbi3\nA88U7tJCGcSX/hbhOirOBgAAAMJJREFU+4Yw5xvi4n9XAkeALy1gfkKoZP+qqv5K8dJZ912vFIvO\nShCyPw8RslU/t+j5bDPHqwiZtT8F7k/zJCxl8lnga8BngAuXYK6fJLhoE0Kc5oPbzZOQcbs1fvdf\nAa5Zojn/yzinewlicElx/M/FOT8IvGdBc34nwZ28F7gn3t677N/1qt+sU8AwjJVh0S6nYRjGnmGC\nZhjGymCCZhjGymCCZhjGymCCZhjGymCCZhjGymCCZhjGymCCZhjGyvD/A7w2F1pRYI7fAAAAAElF\nTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATQAAAD8CAYAAAD5TVjyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 2, 3, 5, 7, 8, 9, 10, 14, 15, 16, 17, 22, 23, 24, 27, 28, 30, 36, 37, 38, 40, 41, 42, 43, 44, 45, 48, 49, 50, 52, 53, 54, 56, 57, 58, 60, 61, 62, 64, 65, 66, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199}\n"
     ]
    }
   ],
   "source": [
    "X_train = train_data[0]\n",
    "Y_train = train_data[1]\n",
    "\n",
    "X_val = val_data[0]\n",
    "Y_val = val_data[1]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "\n",
    "# This will show a slice of a patient\n",
    "ind = 700\n",
    "patient = X_train[ind, :, :, :]\n",
    "patient_labels = Y_train[ind, :, :]\n",
    "plt.imshow(patient[:, :, 0])\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "plt.imshow(patient_labels[:, :, 1])\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "print(train_data[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3705e3NYZ5ln"
   },
   "source": [
    "# New main training cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab_type": "code",
    "id": "8JHoeyzwFW9T",
    "outputId": "7c142486-2ee7-4549-b2ef-8b968ea766aa",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54.0
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'weights_path': '/content/my_drive/My Drive/EXJOBB/training_sessions/unet_softmax_t1ce_whole_tumor_z_score/weights.h5', 'config_path': '/content/my_drive/My Drive/EXJOBB/training_sessions/unet_softmax_t1ce_whole_tumor_z_score/config.json', 'samples_used': 90, 'keep_training': False, 'history': {'training_samples_used': 0, 'loss': [], 'val_loss': []}}\n"
     ]
    }
   ],
   "source": [
    "# Load config file to session here\n",
    "if run_on_colab:\n",
    "    config_path = path + \"EXJOBB/training_sessions/unet_softmax_t1ce_whole_tumor_z_score/config.json\"\n",
    "    weights_path = path + \"EXJOBB/training_sessions/unet_softmax_t1ce_whole_tumor_z_score/weights.h5\"\n",
    "else:\n",
    "    config_path = \"config_0.json\"\n",
    "\n",
    "with open(config_path, 'r') as config_file:\n",
    "    config = json.load(config_file)\n",
    "\n",
    "# Reset file to empty loss-values and/or change paths to config and weights\n",
    "reset_config(config)\n",
    "\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code",
    "id": "oFp9Vq4udUGo",
    "outputId": "dea9d8d2-4ba0-4190-ac05-a3813aa83190",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 836.0
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "# The path to where to save weights and initialize ModelCheckpoint\n",
    "weights_path = config['weights_path']\n",
    "MyModelCheckPoint = ModelCheckpoint(weights_path, verbose=0, save_weights_only=True, period=1)\n",
    "\n",
    "log_dir=path+\"EXJOBB/training_sessions/unet_softmax_t1ce_whole_tumor_z_score/logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "reset_config(config, config_path = config_path, weights_path=weights_path)\n",
    "\n",
    "if config['keep_training'] == True:\n",
    "    # Keep training on the old weights\n",
    "    my_unet = unet(input_size = (240, 240, 1), num_classes=2, pretrained_weights = weights_path)\n",
    "else:\n",
    "    # Initialize network\n",
    "    my_unet = unet(input_size = (240, 240, 1), num_classes=2)\n",
    "    config['keep_training'] = True\n",
    "\n",
    "assert not np.any(np.isnan(X_train)), 'Input contain nans'\n",
    "\n",
    "#Y_train = Y_train.reshape(Y_train.shape[0], -1, 4)\n",
    "validation_data = (X_val, Y_val.reshape(-1, 240**2, 2))\n",
    "\n",
    "history = my_unet.fit(x=X_train, \n",
    "                      y=Y_train.reshape(-1, 240**2, 2), \n",
    "                      batch_size=128,\n",
    "                      epochs=15, \n",
    "                      verbose=1, \n",
    "                      callbacks=[CallbackJSON(config=config), MyModelCheckPoint, es, tensorboard_callback],\n",
    "                      validation_split=0.0, \n",
    "                      validation_data=validation_data, \n",
    "                      shuffle=True, \n",
    "                      class_weight=None, \n",
    "                      sample_weight=None, \n",
    "                      initial_epoch=0, \n",
    "                      steps_per_epoch=None, \n",
    "                      validation_steps=None, \n",
    "                      validation_freq=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First cell plots the loss and validation loss values per epoch.\n",
    "Second cell plots the prediction of the current network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code",
    "id": "qfr5L5aFNKvc",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "loss = config['history']['loss']\n",
    "val_loss = config['history']['val_loss']\n",
    "plt.plot(loss)\n",
    "plt.plot(val_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code",
    "id": "AEz-JB1iNKve",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "ind = 75\n",
    "my_unet = unet(input_size=(240, 240, 1), num_classes=2, pretrained_weights=weights_path)\n",
    "x = val_data[0][ind, :, :, 0].reshape(1, 240, 240, 1)\n",
    "yhat = my_unet.predict(x)\n",
    "yhat = yhat.reshape((240, 240, 2))\n",
    "plotable = np.argmax(yhat, axis=2)\n",
    "plt.imshow(plotable)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "plt.imshow(val_data[1][ind, :, :, 1])\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "name": "Copy of segmentation_brats_colab.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true,
   "machine_shape": "hm"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
