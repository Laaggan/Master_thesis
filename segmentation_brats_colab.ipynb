{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pc0e7NjANKvB"
   },
   "source": [
    "Linus code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4245,
     "status": "ok",
     "timestamp": 1571900254797,
     "user": {
      "displayName": "Linus Lagergren",
      "photoUrl": "",
      "userId": "10069920663213268691"
     },
     "user_tz": -60
    },
    "id": "uDKIINKU_HFe",
    "outputId": "707becce-fda6-4c98-f133-0e2d16781638"
   },
   "outputs": [],
   "source": [
    "# Install package to be able to save keras weights\n",
    "pip install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6781,
     "status": "ok",
     "timestamp": 1571900257347,
     "user": {
      "displayName": "Linus Lagergren",
      "photoUrl": "",
      "userId": "10069920663213268691"
     },
     "user_tz": -60
    },
    "id": "L06f9hdTEJVq",
    "outputId": "2286fbc3-6317-44b3-af24-247834ff9f9f"
   },
   "outputs": [],
   "source": [
    "pip install nibabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8960,
     "status": "ok",
     "timestamp": 1571900259551,
     "user": {
      "displayName": "Linus Lagergren",
      "photoUrl": "",
      "userId": "10069920663213268691"
     },
     "user_tz": -60
    },
    "id": "5et-JeLXj3BG",
    "outputId": "276bd8e9-a060-4ea6-8195-11d998621178"
   },
   "outputs": [],
   "source": [
    "# Mount google drive\n",
    "from google.colab import drive\n",
    "import os\n",
    "drive.mount('my_drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 17822,
     "status": "ok",
     "timestamp": 1571900268457,
     "user": {
      "displayName": "Linus Lagergren",
      "photoUrl": "",
      "userId": "10069920663213268691"
     },
     "user_tz": -60
    },
    "id": "XN2r9qPvNKvJ",
    "outputId": "ba8ef823-4a05-4cae-bddb-a17e2e09c519"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished\n",
      "0.734507008\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import Callback\n",
    "import keras.backend as K\n",
    "import json\n",
    "import psutil\n",
    "import glob\n",
    "import nibabel as nib\n",
    "import os\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.activations import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as keras\n",
    "\n",
    "def print_memory_use():\n",
    "    '''\n",
    "    Function which prints current python memory usage\n",
    "    '''\n",
    "    process = psutil.Process(os.getpid())\n",
    "    print(process.memory_info().rss/1e9)\n",
    "\n",
    "# What value maps to what class\n",
    "mapping = {\n",
    "    0: \"Null class\",\n",
    "    1: \"Necrotic and non-enhancing tumor core\",\n",
    "    2: \"Edema\",\n",
    "    4: \"GD-enhancing tumor\"\n",
    "}\n",
    "\n",
    "mapping2 = {\n",
    "    0: \"Null class\",\n",
    "    1: \"Tumor\",\n",
    "}\n",
    "\n",
    "# fixme: skulle gå att göra bättre igenom att skicka med en tex tuple med titlarna\n",
    "# och returnera ett matplotlib-objekt istället för då hade man inte behövt ha olika\n",
    "# funktioner för \"plot_modalities\" och \"plt_OHE\" och också kunna ha två stycken figurer med \n",
    "# 2*2 subplots i en cell.\n",
    "def plot_modalities(x):\n",
    "    # Make sure input data is of correct shape\n",
    "    assert x.shape == (240, 240, 4), 'Shape of input data is incorrect'\n",
    "    \n",
    "    plt.subplot('221')\n",
    "    plt.imshow(x[:,:,0])\n",
    "    plt.axis('off')\n",
    "    plt.title('T1')\n",
    "    plt.colorbar()\n",
    "\n",
    "    plt.subplot('222')\n",
    "    plt.imshow(x[:,:,1])\n",
    "    plt.axis('off')\n",
    "    plt.title('T1ce')\n",
    "    plt.colorbar()\n",
    "\n",
    "    plt.subplot('223')\n",
    "    plt.imshow(x[:,:,2])\n",
    "    plt.axis('off')\n",
    "    plt.title('T2')\n",
    "    plt.colorbar()\n",
    "\n",
    "    plt.subplot('224')\n",
    "    plt.imshow(x[:,:,3])\n",
    "    plt.axis('off')\n",
    "    plt.title('FLAIR')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "def plot_OHE(y):\n",
    "    # Make sure input data is of correct shape\n",
    "    assert y.shape == (240, 240, 4), 'Shape of input data is incorrect'\n",
    "    \n",
    "    plt.subplot('221')\n",
    "    plt.imshow(y[:,:,0])\n",
    "    plt.axis('off')\n",
    "    plt.title('Null')\n",
    "    plt.colorbar()\n",
    "\n",
    "    plt.subplot('222')\n",
    "    plt.imshow(y[:,:,1])\n",
    "    plt.axis('off')\n",
    "    plt.title('\"Necrotic and non-enhancing tumor core\"')\n",
    "    plt.colorbar()\n",
    "\n",
    "    plt.subplot('223')\n",
    "    plt.imshow(y[:,:,2])\n",
    "    plt.axis('off')\n",
    "    plt.title('Edema')\n",
    "    plt.colorbar()\n",
    "\n",
    "    plt.subplot('224')\n",
    "    plt.imshow(y[:,:,3])\n",
    "    plt.axis('off')\n",
    "    plt.title('GD-enhancing tumor')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "def shift_and_scale(x):\n",
    "    assert len(x.shape) == 2, 'The input must be 2 dimensional'\n",
    "    #assert np.std(x) != 0, 'Cant divide by zero'\n",
    "    result = x - np.mean(x)\n",
    "    \n",
    "    # This is a really ugly hack\n",
    "    if np.std(x) == 0:\n",
    "        result /= 1\n",
    "    else:\n",
    "        result /= np.std(x)\n",
    "    return result\n",
    "\n",
    "def OHE(Y, mapping):\n",
    "    '''\n",
    "    Takes in a picture as a matrix with labels and returns a one hot encoded tensor\n",
    "    \n",
    "    Parameters:\n",
    "    Y is the picture\n",
    "    Mapping is what value corresponds to what label\n",
    "    \n",
    "    Returns:\n",
    "    A tensor with a channel for each label.\n",
    "    '''\n",
    "    shape = Y.shape\n",
    "    labels = mapping.keys()\n",
    "    one_hot_enc = np.zeros(list(shape) + [len(labels)])\n",
    "    \n",
    "    for i, label in enumerate(labels):\n",
    "        temp = np.zeros(shape)\n",
    "        ind = Y == label\n",
    "        temp[ind] = 1\n",
    "        one_hot_enc[:, :, i] = temp\n",
    "    return one_hot_enc\n",
    "\n",
    "def OHE2(Y):\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    shape = Y.shape\n",
    "    # fixme: Having a OHE-encoding now is unnecessary\n",
    "    # 1 channels encodes all informations\n",
    "    one_hot_enc = np.zeros(list(shape) + [2])\n",
    "    temp = np.zeros(shape)\n",
    "    temp2 = np.ones(shape)\n",
    "    \n",
    "    ind1 = Y == 1\n",
    "    ind2 = Y == 4\n",
    "    temp[ind1] = 1\n",
    "    temp[ind2] = 1\n",
    "    \n",
    "    temp2 = temp2 - temp\n",
    "    \n",
    "    one_hot_enc[:, :, 0] = temp\n",
    "    one_hot_enc[:, :, 1] = temp2\n",
    "    return one_hot_enc\n",
    "\n",
    "def convert_brats(Y):\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    shape = Y.shape\n",
    "    # fixme: Having a OHE-encoding now is unnecessary\n",
    "    # 1 channels encodes all informations\n",
    "    result = np.zeros(shape)\n",
    "    temp = np.zeros(shape)\n",
    "    \n",
    "    ind1 = Y == 1\n",
    "    ind2 = Y == 4\n",
    "    temp[ind1] = 1\n",
    "    temp[ind2] = 1\n",
    "    \n",
    "    result = temp\n",
    "    return result\n",
    "\n",
    "#fixme: I don't know if providing this mapping is necessary\n",
    "# probably could be provided inside function instead.\n",
    "def OHE_uncoding(y, mapping):\n",
    "    result = np.argmax(y, axis=2)\n",
    "    labels = mapping.keys()\n",
    "    temp = np.zeros(result.shape)\n",
    "    for i, label in enumerate(labels):\n",
    "        ind = result == i\n",
    "        temp[ind] = label\n",
    "    return temp\n",
    "\n",
    "def IoU_wholeTumor(y_true, y_pred):\n",
    "    values = np.array([0., 1.])\n",
    "    unique_y_pred = np.unique(y_pred)\n",
    "    unique_y_true = np.unique(y_true)\n",
    "    assert np.array_equal(y_pred.shape, y_true.shape), 'Prediction and ground truth must have same shape'\n",
    "    assert np.array_equal(values, unique_y_pred), 'yhat and y must be one hot encodings'\n",
    "    assert np.array_equal(values, unique_y_true), 'yhat and y must be one hot encodings'\n",
    "    \n",
    "    \n",
    "    y_pred[:,:,0] = np.logical_not(y_pred[:,:,0]) \n",
    "    y_true[:,:,0] = np.logical_not(y_true[:,:,0])\n",
    "    \n",
    "    intersection = np.logical_and(y_pred[:,:,0], y_true[:,:,0])\n",
    "    union = np.logical_or(y_true[:,:,0], y_pred[:,:,0])\n",
    "    \n",
    "    size_int = np.count_nonzero(intersection)\n",
    "    size_uni = np.count_nonzero(union)\n",
    "    \n",
    "    return size_int/size_uni\n",
    "\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(K.abs(y_true_f * y_pred_f), axis=-1)\n",
    "    return (2. * intersection) / (\n",
    "        K.sum(K.square(y_true_f), -1) + K.sum(K.square(y_pred_f), -1) + 1e-8)\n",
    "\n",
    "def IoU(y_true, y_pred):\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
    "    sum_ = K.sum(K.abs(y_true) + K.abs(y_pred), axis=-1)\n",
    "    return intersection/sum_\n",
    "\n",
    "def ful_IoU(y_true, y_pred):\n",
    "    intersection = K.cast(np.sum(K.eval(y_true)[:,0] == K.eval(y_pred)[:,0]), dtype='float32')\n",
    "    y1 = (K.eval(y_true)[:,0] > 0)\n",
    "    y2 = (K.eval(y_pred)[:,0] > 0)\n",
    "    union = K.cast(np.sum((y1 + y2) > 0), dtype='float32')\n",
    "    return intersection/union\n",
    "\n",
    "def confusion_matrix(y_true, y_pred):\n",
    "    values = np.array([0., 1.])\n",
    "    unique_y_pred = np.unique(y_pred)\n",
    "    unique_y_true = np.unique(y_true)\n",
    "    assert np.array_equal(y_pred.shape, y_true.shape), 'Prediction and ground truth must have same shape'\n",
    "    assert np.array_equal(values, unique_y_pred), 'yhat and y must be one hot encodings'\n",
    "    assert np.array_equal(values, unique_y_true), 'yhat and y must be one hot encodings'\n",
    "    \n",
    "    p_00 = np.count_nonzero(np.logical_and(y_pred[:,:,0], y_true[:,:,0]))\n",
    "    p_11 = np.count_nonzero(np.logical_and(y_pred[:,:,1], y_true[:,:,1]))\n",
    "    p_22 = np.count_nonzero(np.logical_and(y_pred[:,:,2], y_true[:,:,2]))\n",
    "    p_33 = np.count_nonzero(np.logical_and(y_pred[:,:,3], y_true[:,:,3]))\n",
    "\n",
    "    f_10 = np.count_nonzero(np.logical_and(y_pred[:,:,0], y_true[:,:,1]))\n",
    "    f_20 = np.count_nonzero(np.logical_and(y_pred[:,:,0], y_true[:,:,2]))\n",
    "    f_30 = np.count_nonzero(np.logical_and(y_pred[:,:,0], y_true[:,:,3]))\n",
    "\n",
    "    f_01 = np.count_nonzero(np.logical_and(y_pred[:,:,1], y_true[:,:,0]))\n",
    "    f_21 = np.count_nonzero(np.logical_and(y_pred[:,:,1], y_true[:,:,2]))\n",
    "    f_31 = np.count_nonzero(np.logical_and(y_pred[:,:,1], y_true[:,:,3]))\n",
    "\n",
    "    f_02 = np.count_nonzero(np.logical_and(y_pred[:,:,2], y_true[:,:,0]))\n",
    "    f_12 = np.count_nonzero(np.logical_and(y_pred[:,:,2], y_true[:,:,1]))\n",
    "    f_32 = np.count_nonzero(np.logical_and(y_pred[:,:,2], y_true[:,:,3]))\n",
    "\n",
    "    f_03 = np.count_nonzero(np.logical_and(y_pred[:,:,3], y_true[:,:,0]))\n",
    "    f_13 = np.count_nonzero(np.logical_and(y_pred[:,:,3], y_true[:,:,1]))\n",
    "    f_23 = np.count_nonzero(np.logical_and(y_pred[:,:,3], y_true[:,:,2]))\n",
    "\n",
    "    conf_matrix = np.array([p_00, f_01, f_02, f_03,\n",
    "                            f_10,p_11, f_12, f_13, \n",
    "                            f_20, f_21, p_22, f_23, \n",
    "                            f_30, f_31, f_32, p_33])\n",
    "    conf_matrix = conf_matrix.reshape(4,4)\n",
    "    \n",
    "    return conf_matrix\n",
    "\n",
    "def reset_config(config, config_path=None, weights_path=None):\n",
    "    new_config = config\n",
    "    if weights_path:\n",
    "        assert type(weights_path) == str, 'The weight path must be a string'\n",
    "        new_config['weights_path'] = weights_path\n",
    "    if config_path:\n",
    "        assert type(config_path) == str, 'The config path must be a string'\n",
    "        new_config['config_path'] = config_path\n",
    "    new_config['history']['training_samples_used'] = 0\n",
    "    new_config['history']['loss'] = []\n",
    "    new_config['history']['val_loss'] = []\n",
    "    new_config['keep_training'] = False\n",
    "\n",
    "class CallbackJSON(Callback):\n",
    "    \"\"\" CallbackJSON descends from Callback\n",
    "        and is used to write the number of training samples that the model has been trained on\n",
    "        and the loss for a epoch\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        \"\"\"Save params in constructor\n",
    "        config: Is a dictionary loaded from a JSON file which is used to keep track of training\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "        self.config_path = config['config_path']\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        \"\"\"\n",
    "        Updates the history of the config dict and saves it to a file\n",
    "        \"\"\"\n",
    "        # How many effective training samples have been used\n",
    "        self.config['history']['training_samples_used'] += self.config['samples_used']\n",
    "        \n",
    "        # Logs the loss of the current epoch\n",
    "        self.config['history']['loss'].append(logs['loss'])\n",
    "        #fixme: add the same code but for \"val_loss\"\n",
    "        self.config['history']['val_loss'].append(logs['val_loss'])\n",
    "        \n",
    "        print_memory_use()\n",
    "        # Save new config file\n",
    "        with open(self.config_path, \"w\") as f:\n",
    "            f.write(json.dumps(self.config))\n",
    "\n",
    "def load_patients(i, j, num_classes, base_path=\"\"):\n",
    "    assert j >= i, 'j>i has to be true, you have given an invalid range of patients.'\n",
    "    \n",
    "    path = base_path + \"MICCAI_BraTS_2019_Data_Training/*/*/*\"\n",
    "    \n",
    "    wild_t1 = path + \"_t1.nii.gz\"\n",
    "    wild_t1ce = path + \"_t1ce.nii.gz\"\n",
    "    wild_t2 = path + \"_t2.nii.gz\"\n",
    "    wild_flair = path + \"_flair.nii.gz\"\n",
    "    wild_gt = path + \"_seg.nii.gz\"\n",
    "    \n",
    "    t1_paths = glob.glob(wild_t1)\n",
    "    t1ce_paths = glob.glob(wild_t1ce)\n",
    "    t2_paths = glob.glob(wild_t2)\n",
    "    flair_paths = glob.glob(wild_flair)\n",
    "    gt_paths = glob.glob(wild_gt)\n",
    "\n",
    "    num_patients = j - i\n",
    "    ind = []\n",
    "    num_non_empty_slices = 0\n",
    "\n",
    "    for i in range(i, i + num_patients):\n",
    "        path_gt = gt_paths[i]\n",
    "        img_gt = nib.load(path_gt)\n",
    "        img_gt = img_gt.get_fdata()\n",
    "\n",
    "        curr_patient = []\n",
    "        # quick and dirty way to only get slices with tumor\n",
    "        for j in range(img_gt.shape[-1]):\n",
    "            if len(np.unique(img_gt[:,:,j])) >= num_classes:\n",
    "                curr_patient.append(j)\n",
    "                num_non_empty_slices += 1\n",
    "        ind.append(curr_patient)\n",
    "\n",
    "    image_data = np.zeros((4, 240, 240, num_non_empty_slices))\n",
    "    labels = np.zeros((num_non_empty_slices, 240, 240))\n",
    "    OHE_labels = np.zeros((num_non_empty_slices, 240, 240, 4))\n",
    "    next_ind = 0\n",
    "\n",
    "    for i in range(num_patients):\n",
    "        print('Patient: ' + str(i))\n",
    "        curr_ind = ind[i]\n",
    "\n",
    "        path_t1 = t1_paths[i]\n",
    "        path_t1ce = t1ce_paths[i]\n",
    "        path_t2 = t2_paths[i]\n",
    "        path_flair = flair_paths[i]\n",
    "        path_gt = gt_paths[i]\n",
    "\n",
    "        img_t1 = nib.load(path_t1)\n",
    "        img_t1ce = nib.load(path_t1ce)\n",
    "        img_t2 = nib.load(path_t2)\n",
    "        img_flair = nib.load(path_flair)\n",
    "        img_gt = nib.load(path_gt)\n",
    "\n",
    "        img_t1 = img_t1.get_fdata()\n",
    "        img_t1ce = img_t1ce.get_fdata()\n",
    "        img_t2 = img_t2.get_fdata()\n",
    "        img_flair = img_flair.get_fdata()\n",
    "        img_gt = img_gt.get_fdata()\n",
    "\n",
    "        temp = 0\n",
    "        for i, x in enumerate(curr_ind):\n",
    "            image_data[0, :, :, next_ind + i] = img_t1[:,:,x]\n",
    "            image_data[1, :, :, next_ind + i] = img_t1ce[:,:,x]\n",
    "            image_data[2, :, :, next_ind + i] = img_t2[:,:,x]\n",
    "            image_data[3, :, :, next_ind + i] = img_flair[:,:,x]\n",
    "            labels[next_ind + i,:,:] = img_gt[:,:,x]\n",
    "            temp += 1\n",
    "        next_ind += temp\n",
    "\n",
    "    # I have here chosen to do shift and scale per image, \n",
    "    # which is not the only way to do normalization.\n",
    "    for j in range(num_non_empty_slices):\n",
    "        # shift and scale data\n",
    "        image_data[0, :, :, j] = shift_and_scale(image_data[0, :, :, j])\n",
    "        image_data[1, :, :, j] = shift_and_scale(image_data[1, :, :, j])\n",
    "        image_data[2, :, :, j] = shift_and_scale(image_data[2, :, :, j])\n",
    "        image_data[3, :, :, j] = shift_and_scale(image_data[3, :, :, j])\n",
    "\n",
    "        OHE_labels[j, :, :, :] = OHE(labels[j, :, :], mapping)\n",
    "\n",
    "    # The last axis will become the first axis\n",
    "    image_data = np.moveaxis(image_data, -1, 0)\n",
    "    image_data = np.moveaxis(image_data, 1, 3)\n",
    "    return (image_data, OHE_labels)\n",
    "\n",
    "def load_patients2(i, j, base_path=\"\"):\n",
    "    assert j >= i, 'j>i has to be true, you have given an invalid range of patients.'\n",
    "    \n",
    "    path = base_path + \"MICCAI_BraTS_2019_Data_Training/*/*/*\"\n",
    "    \n",
    "    wild_t1ce = path + \"_t1ce.nii.gz\"\n",
    "    wild_gt = path + \"_seg.nii.gz\"\n",
    "    \n",
    "    t1ce_paths = glob.glob(wild_t1ce)\n",
    "    gt_paths = glob.glob(wild_gt)\n",
    "\n",
    "    num_patients = j - i\n",
    "    ind = []\n",
    "    num_non_empty_slices = 0\n",
    "\n",
    "    for k in range(i, j):\n",
    "        path_gt = gt_paths[k]\n",
    "        img_gt = nib.load(path_gt)\n",
    "        img_gt = img_gt.get_fdata()\n",
    "\n",
    "        curr_patient = []\n",
    "        for l in range(img_gt.shape[-1]):\n",
    "            labels_in_slice = set(np.unique(img_gt[:,:,l]))\n",
    "            labels_of_interest = set([1,4])\n",
    "            if labels_of_interest.issubset(labels_in_slice):\n",
    "                curr_patient.append(l)\n",
    "                num_non_empty_slices += 1\n",
    "        ind.append(curr_patient)\n",
    "\n",
    "    image_data = np.zeros((1, 240, 240, num_non_empty_slices))\n",
    "    labels = np.zeros((num_non_empty_slices, 240, 240))\n",
    "    OHE_labels = np.zeros((num_non_empty_slices, 240, 240, 2))\n",
    "    next_ind = 0\n",
    "\n",
    "    for k in range(len(ind)):\n",
    "        print('Patient: ' + str(k))\n",
    "        curr_ind = ind[k]\n",
    "\n",
    "        path_t1ce = t1ce_paths[k]\n",
    "        path_gt = gt_paths[k]\n",
    "\n",
    "        img_t1ce = nib.load(path_t1ce)\n",
    "        img_gt = nib.load(path_gt)\n",
    "\n",
    "        img_t1ce = img_t1ce.get_fdata()\n",
    "        img_gt = img_gt.get_fdata()\n",
    "\n",
    "        temp = 0\n",
    "        for l, x in enumerate(curr_ind):\n",
    "            image_data[0, :, :, next_ind + l] = img_t1ce[:,:,x]\n",
    "            labels[next_ind + l,:,:] = img_gt[:,:,x]\n",
    "            temp += 1\n",
    "        next_ind += temp\n",
    "\n",
    "    for l in range(num_non_empty_slices):\n",
    "        image_data[0, :, :, l] = shift_and_scale(image_data[0, :, :, l])\n",
    "        OHE_labels[l, :, :, :] = OHE2(labels[l, :, :])\n",
    "\n",
    "    # The last axis will become the first axis\n",
    "    image_data = np.moveaxis(image_data, -1, 0)\n",
    "    image_data = np.moveaxis(image_data, 1, 3)\n",
    "    return (image_data, OHE_labels)\n",
    "\n",
    "def load_patients3(i, j, base_path=\"\"):\n",
    "    assert j >= i, 'j>i has to be true, you have given an invalid range of patients.'\n",
    "    \n",
    "    path = base_path + \"MICCAI_BraTS_2019_Data_Training/*/*/*\"\n",
    "    \n",
    "    wild_t1ce = path + \"_t1ce.nii.gz\"\n",
    "    wild_gt = path + \"_seg.nii.gz\"\n",
    "    \n",
    "    t1ce_paths = glob.glob(wild_t1ce)\n",
    "    gt_paths = glob.glob(wild_gt)\n",
    "\n",
    "    num_patients = j - i\n",
    "    ind = []\n",
    "    num_non_empty_slices = 0\n",
    "\n",
    "    for k in range(i, i + num_patients):\n",
    "        path_gt = gt_paths[k]\n",
    "        img_gt = nib.load(path_gt)\n",
    "        img_gt = img_gt.get_fdata()\n",
    "\n",
    "        curr_patient = []\n",
    "        # Get slices containing class 1 and 4\n",
    "        for l in range(img_gt.shape[-1]):\n",
    "            labels_in_slice = set(np.unique(img_gt[:,:,l]))\n",
    "            labels_of_interest = set([1,4])\n",
    "            if labels_of_interest.issubset(labels_in_slice):\n",
    "                curr_patient.append(l)\n",
    "                num_non_empty_slices += 1\n",
    "        ind.append(curr_patient)\n",
    "\n",
    "    image_data = np.zeros((1, 240, 240, num_non_empty_slices))\n",
    "    labels = np.zeros((num_non_empty_slices, 240, 240))\n",
    "    next_ind = 0\n",
    "\n",
    "    for k in range(num_patients):\n",
    "        print('Patient: ' + str(k))\n",
    "        curr_ind = ind[k]\n",
    "\n",
    "        path_t1ce = t1ce_paths[k]\n",
    "        path_gt = gt_paths[k]\n",
    "\n",
    "        img_t1ce = nib.load(path_t1ce)\n",
    "        img_gt = nib.load(path_gt)\n",
    "\n",
    "        img_t1ce = img_t1ce.get_fdata()\n",
    "        img_gt = img_gt.get_fdata()\n",
    "\n",
    "        temp = 0\n",
    "        for l, x in enumerate(curr_ind):\n",
    "            image_data[0, :, :, next_ind + l] = img_t1ce[:,:,x]\n",
    "            labels[next_ind + l,:,:] = img_gt[:,:,x]\n",
    "            temp += 1\n",
    "        next_ind += temp\n",
    "\n",
    "    # I have here chosen to do shift and scale per image, \n",
    "    # which is not the only way to do normalization.\n",
    "    for l in range(num_non_empty_slices):\n",
    "        # shift and scale data\n",
    "        image_data[0, :, :, j] = shift_and_scale(image_data[0, :, :, l])\n",
    "        labels[l, :, :] = convert_brats(labels[l, :, :])\n",
    "\n",
    "    # The last axis will become the first axis\n",
    "    image_data = np.moveaxis(image_data, -1, 0)\n",
    "    image_data = np.moveaxis(image_data, 1, 3)\n",
    "    return (image_data, labels)\n",
    "\n",
    "def unet_binary(pretrained_weights = None, input_size = (256,256,1)):\n",
    "    inputs = Input(input_size)\n",
    "    #args = dict(activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "    merge6 = concatenate([drop4,up6], axis = 3)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "    merge9 = concatenate([conv1,up9], axis = 3)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv10 = Conv2D(1, 1, activation = 'softmax')(conv9)\n",
    "\n",
    "    model = Model(input = inputs, output = conv10)\n",
    "\n",
    "    model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = [IoU, dice_coefficient])\n",
    "    \n",
    "    #model.summary()\n",
    "\n",
    "    if(pretrained_weights):\n",
    "    \tmodel.load_weights(pretrained_weights)\n",
    "\n",
    "    return model\n",
    "\n",
    "def unet(pretrained_weights = None, input_size = (256, 256, 1), num_classes=1, learning_rate=1e-4):\n",
    "    inputs = Input(input_size)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size = (2, 2))(conv1)\n",
    "    \n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size = (2, 2))(conv2)\n",
    "    \n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size = (2, 2))(conv3)\n",
    "    \n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size = (2, 2))(drop4)\n",
    "    \n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "    \n",
    "    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2, 2))(drop5))\n",
    "    merge6 = concatenate([drop4, up6], axis = 3)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "    \n",
    "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2, 2))(conv6))\n",
    "    merge7 = concatenate([conv3, up7], axis = 3)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "    \n",
    "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2, 2))(conv7))\n",
    "    merge8 = concatenate([conv2, up8], axis = 3)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "    \n",
    "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2, 2))(conv8))\n",
    "    merge9 = concatenate([conv1, up9], axis = 3)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9 = Conv2D(num_classes, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    \n",
    "    reshape = Reshape((num_classes, input_size[0] * input_size[1]), input_shape = (num_classes, input_size[0], input_size[1]))(conv9)\n",
    "    permute = Permute((2, 1))(reshape)\n",
    "    activation = Softmax(axis=-1)(permute)\n",
    "    \n",
    "    model = Model(input = inputs, output = activation)\n",
    "    model.compile(optimizer = Adam(lr=learning_rate), loss = 'categorical_crossentropy', metrics=[dice_coefficient])\n",
    "    if (pretrained_weights):\n",
    "        model.load_weights(pretrained_weights)\n",
    "    return model\n",
    "\n",
    "def unet_res(pretrained_weights = None, input_size = (256, 256, 4), num_classes=4, learning_rate=1e-4, dropout=0.5, this_activation='relu'):\n",
    "    inputs = Input(input_size)\n",
    "    conv1 = Conv2D(64, 3, activation = this_activation, padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation = this_activation, padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    conv1 = Conv2D(input_size[-1], 1, activation = 'linear', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    merge1 = Add()([inputs, conv1])\n",
    "    merge1 = BatchNormalization()(merge1)\n",
    "    merge1 = Activation(this_activation)(merge1)\n",
    "    pool1 = MaxPooling2D(pool_size = (2, 2))(merge1)\n",
    "    \n",
    "    conv2 = Conv2D(128, 3, activation = this_activation, padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation = this_activation, padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    conv2 = Conv2D(input_size[-1], 1, activation = 'linear', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    merge2 = Add()([pool1, conv2])\n",
    "    merge2 = BatchNormalization()(merge2)\n",
    "    merge2 = Activation(this_activation)(merge2)\n",
    "    pool2 = MaxPooling2D(pool_size = (2, 2))(merge2)\n",
    "    \n",
    "    conv3 = Conv2D(256, 3, activation = this_activation, padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation = this_activation, padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    conv3 = Conv2D(input_size[-1], 1, activation = 'linear', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    merge3 = Add()([pool2, conv3])\n",
    "    merge3 = BatchNormalization()(merge3)\n",
    "    merge3 = Activation(this_activation)(merge3)\n",
    "    pool3 = MaxPooling2D(pool_size = (2, 2))(merge3)\n",
    "    \n",
    "    conv4 = Conv2D(512, 3, activation = this_activation, padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation = this_activation, padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    drop4 = Dropout(dropout)(conv4)\n",
    "    drop4 = Conv2D(input_size[-1], 1, activation = 'linear', padding = 'same', kernel_initializer = 'he_normal')(drop4)\n",
    "    merge4 = Add()([pool3, drop4])\n",
    "    merge4 = BatchNormalization()(merge4)\n",
    "    merge4 = Activation(this_activation)(merge4)\n",
    "    pool4 = MaxPooling2D(pool_size = (2, 2))(merge4)\n",
    "    \n",
    "    conv5 = Conv2D(1024, 3, activation = this_activation, padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "    conv5 = Conv2D(1024, 3, activation = this_activation, padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "    drop5 = Dropout(dropout)(conv5)\n",
    "    drop5 = Conv2D(input_size[-1], 1, activation = 'linear', padding = 'same', kernel_initializer = 'he_normal')(drop5)\n",
    "    merge5 = Add()([pool4, drop5])\n",
    "    merge5 = BatchNormalization()(merge5)\n",
    "    merge5 = Activation(this_activation)(merge5)\n",
    "    \n",
    "    up6 = Conv2D(input_size[-1], 2, activation = this_activation, padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2, 2))(merge5))\n",
    "    merge6 = concatenate([merge4, up6], axis = 3)\n",
    "    conv6 = Conv2D(512, 3, activation = this_activation, padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6 = Conv2D(512, 3, activation = this_activation, padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "    conv6 = Conv2D(2*input_size[-1], 1, activation = 'linear', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "    merge6 = Add()([merge6, conv6])\n",
    "    merge6 = BatchNormalization()(merge6)\n",
    "    merge6 = Activation(this_activation)(merge6)\n",
    "    \n",
    "    up7 = Conv2D(input_size[-1], 2, activation = this_activation, padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2, 2))(merge6))\n",
    "    merge7 = concatenate([merge3, up7], axis = 3)\n",
    "    conv7 = Conv2D(256, 3, activation = this_activation, padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation = this_activation, padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "    conv7 = Conv2D(2*input_size[-1], 1, activation = 'linear', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "    merge7 = Add()([merge7, conv7])\n",
    "    merge7 = BatchNormalization()(merge7)\n",
    "    merge7 = Activation(this_activation)(merge7)\n",
    "    \n",
    "    up8 = Conv2D(input_size[-1], 2, activation = this_activation, padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2, 2))(merge7))\n",
    "    merge8 = concatenate([merge2, up8], axis = 3)\n",
    "    conv8 = Conv2D(128, 3, activation = this_activation, padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation = this_activation, padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "    conv8 = Conv2D(2*input_size[-1], 1, activation = 'linear', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "    merge8 = Add()([merge8, conv8])\n",
    "    merge8 = BatchNormalization()(merge8)\n",
    "    merge8 = Activation(this_activation)(merge8)\n",
    "    \n",
    "    up9 = Conv2D(input_size[-1], 2, activation = this_activation, padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2, 2))(merge8))\n",
    "    merge9 = concatenate([merge1, up9], axis = 3)\n",
    "    conv9 = Conv2D(64, 3, activation = this_activation, padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation = this_activation, padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9 = Conv2D(num_classes, 3, activation = this_activation, padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9 = Conv2D(2*input_size[-1], 1, activation = 'linear', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    merge9 = Add()([merge9, conv9])\n",
    "    merge9 = BatchNormalization()(merge9)\n",
    "    merge9 = Activation(this_activation)(merge9)\n",
    "    \n",
    "    merge10 = Conv2D(input_size[-1], 1, activation = 'linear', padding ='same', kernel_initializer = 'he_normal')(merge9)\n",
    "    \n",
    "    reshape = Reshape((num_classes, input_size[0] * input_size[1]), input_shape = (num_classes, input_size[0], input_size[1]))(merge10)\n",
    "    permute = Permute((2, 1))(reshape)\n",
    "    activation = Softmax(axis=-1)(permute)\n",
    "    \n",
    "    model = Model(input = inputs, output = activation)\n",
    "    model.compile(optimizer = Adam(lr=learning_rate), loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
    "    if (pretrained_weights):\n",
    "        model.load_weights(pretrained_weights)\n",
    "    return model\n",
    "\n",
    "def conv_block(input_, num_kernels, kernel_size, act_func, drop_rate):\n",
    "    conv = Conv2D(num_kernels, kernel_size,activation = act_func, padding = 'same', kernel_initializer = 'he_normal')(input_)\n",
    "    conv = Conv2D(num_kernels, kernel_size, activation = act_func, padding = 'same', kernel_initializer = 'he_normal')(conv)\n",
    "    drop = Dropout(drop_rate)(conv)\n",
    "    return conv\n",
    "\n",
    "def conv_block(input_, num_kernels, kernel_size, act_func, drop_rate):\n",
    "    argz = [num_kernels, kernel_size]\n",
    "    kwargz = {'activation':act_func, 'padding':'same', 'kernel_initializer':'he_normal'}\n",
    "    conv = Conv2D(*argz, **kwargz)(input_)\n",
    "    conv = Conv2D(*argz, **kwargz)(conv)\n",
    "    drop = Dropout(drop_rate)(conv)\n",
    "    return conv\n",
    "\n",
    "def conv_block_resnet(input_, num_kernels, kernel_size, act_func, drop_rate, input_size):\n",
    "    argz = [num_kernels, kernel_size]\n",
    "    kwargz = {'activation':act_func, 'padding':'same', 'kernel_initializer':'he_normal'}\n",
    "    conv = Conv2D(*argz, **kwargz)(input_)\n",
    "    conv = Conv2D(*argz, **kwargz)(conv)\n",
    "    conv = Conv2D(input_size[-1], (1,1), activation = 'linear', padding = 'same', kernel_initializer = 'he_normal')(conv)\n",
    "    conv = Dropout(drop_rate)(conv)\n",
    "    merge = Add()([input_, conv])\n",
    "    merge = BatchNormalization()(merge)\n",
    "    merge = Activation(act_func)(merge)\n",
    "    return merge\n",
    "\n",
    "def down_sampling_block(input_, act_func, num_kernels, drop_rate, input_size, res=False):\n",
    "    if res:\n",
    "        skip = conv_block_resnet(input_=input_, num_kernels=num_kernels, kernel_size=(3,3), \n",
    "                                 act_func=act_func, drop_rate=drop_rate, input_size=input_size)\n",
    "    else:\n",
    "        skip = conv_block(input_, num_kernels=num_kernels, kernel_size=(3,3), act_func=act_func, drop_rate=drop_rate)\n",
    "    pool = MaxPooling2D(pool_size = (2, 2))(skip)\n",
    "    return skip, pool\n",
    "\n",
    "def up_sampling_block(input_, skip, act_func, num_kernels, drop_rate, input_size, res=False):\n",
    "    up = UpSampling2D(size = (2, 2))(input_)\n",
    "    merge = concatenate([skip, up], axis = 3)\n",
    "    if res:\n",
    "        conv = conv_block_resnet(up, num_kernels=num_kernels, kernel_size=(3,3), \n",
    "                                 act_func=act_func, drop_rate=drop_rate, input_size=input_size)\n",
    "    else:\n",
    "        conv = conv_block(merge, num_kernels, (3,3), act_func, drop_rate)\n",
    "    return conv\n",
    "\n",
    "def unet_clean(pretrained_weights = None, input_size = (256, 256, 1), num_classes=2, learning_rate=1e-4, act_func='relu', res=False):\n",
    "    # Encoder\n",
    "    inputs = Input(input_size)\n",
    "    skip1, pool1 = down_sampling_block(inputs, act_func, num_kernels=64, drop_rate=0, input_size = input_size, res=res)\n",
    "    skip2, pool2 = down_sampling_block(pool1, act_func, num_kernels=128, drop_rate=0, input_size = input_size, res=res)\n",
    "    skip3, pool3 = down_sampling_block(pool2, act_func, num_kernels=256, drop_rate=0, input_size = input_size, res=res)\n",
    "    skip4, pool4 = down_sampling_block(pool3, act_func, num_kernels=512, drop_rate=0.2, input_size = input_size, res=res)\n",
    "    \n",
    "    #Bottleneck\n",
    "    conv5 = conv_block(pool4, 1024, 3, act_func, drop_rate=0.2)\n",
    "    \n",
    "    # Decoder\n",
    "    conv6 = up_sampling_block(conv5, skip4, act_func, 512, drop_rate = 0.2, input_size = input_size, res=res)\n",
    "    conv7 = up_sampling_block(conv6, skip3, act_func, 256, drop_rate = 0, input_size = input_size, res=res)\n",
    "    conv8 = up_sampling_block(conv7, skip2, act_func, 128, drop_rate = 0, input_size = input_size, res=res)\n",
    "    conv9 = up_sampling_block(conv8, skip1, act_func, 64, drop_rate = 0, input_size = input_size, res=res)\n",
    "    conv9 = Conv2D(num_classes, 1, activation = act_func, padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "\n",
    "    reshape = Reshape((num_classes, input_size[0] * input_size[1]), input_shape = (num_classes, input_size[0], input_size[1]))(conv9)\n",
    "    permute = Permute((2, 1))(reshape)\n",
    "    activation = Softmax(axis=-1)(permute)\n",
    "    \n",
    "    model = Model(input = inputs, output = activation)\n",
    "    model.compile(optimizer = Adam(lr=learning_rate), loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
    "    if (pretrained_weights):\n",
    "        model.load_weights(pretrained_weights)\n",
    "    return model\n",
    "\n",
    "def unet_depth(pretrained_weights = None, input_size = (256, 256, 1), num_classes=2, learning_rate=1e-4, act_func='relu', res=False, \n",
    "               depth=4, num_kernels = [64, 128, 256, 512]):\n",
    "    assert depth == len(num_kernels), 'Depth and number of kernel sizes must be equal'\n",
    "    \n",
    "    encoder = []\n",
    "    inputs = Input(input_size)\n",
    "    for i in range(depth):\n",
    "        if i == 0:\n",
    "            skip, conv = down_sampling_block(inputs, act_func, num_kernels=num_kernels[i], drop_rate=0, input_size = input_size, res=res)\n",
    "            result = [skip, conv]\n",
    "            encoder.append(result)\n",
    "        else:\n",
    "            skip, conv = down_sampling_block(encoder[i-1][1], act_func, num_kernels=num_kernels[i], drop_rate=0, input_size = input_size, res=res)\n",
    "            result = [skip, conv]\n",
    "            encoder.append(result)\n",
    "\n",
    "    bottleneck = conv_block(encoder[depth - 1][1], 1024, 3, act_func, drop_rate=0.2)\n",
    "\n",
    "    decoder = []\n",
    "    for i in range(depth):\n",
    "        if i == 0:\n",
    "            skip = encoder[depth - 1][0]\n",
    "            decoder.append(up_sampling_block(bottleneck, skip, act_func, num_kernels=num_kernels[depth - i - 1], drop_rate=0, input_size = input_size, res=res))\n",
    "        else:\n",
    "            skip = encoder[depth - i - 1][0]\n",
    "            decoder.append(up_sampling_block(decoder[i - 1], skip, act_func, num_kernels=num_kernels[depth - i - 1], drop_rate=0, input_size = input_size, res=res))\n",
    "            \n",
    "    # prepare for softmax\n",
    "    conv = Conv2D(num_classes, 1, activation = act_func, padding = 'same', kernel_initializer = 'he_normal')(decoder[depth - 1])\n",
    "    reshape = Reshape((num_classes, input_size[0] * input_size[1]), input_shape = (num_classes, input_size[0], input_size[1]))(conv)\n",
    "    permute = Permute((2, 1))(reshape)\n",
    "    activation = Softmax(axis=-1)(permute)\n",
    "    \n",
    "    # Compile model and load pretrained weights\n",
    "    model = Model(input = inputs, output = activation)\n",
    "    model.compile(optimizer = Adam(lr=learning_rate), loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
    "    if (pretrained_weights):\n",
    "        model.load_weights(pretrained_weights)\n",
    "    return model\n",
    "\n",
    "print('Finished')\n",
    "print_memory_use()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 321898,
     "status": "ok",
     "timestamp": 1571900572557,
     "user": {
      "displayName": "Linus Lagergren",
      "photoUrl": "",
      "userId": "10069920663213268691"
     },
     "user_tz": -60
    },
    "id": "9lAteXmGZPqL",
    "outputId": "5a4c1e0c-0b03-4203-c40d-5d91bf7a445e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient: 0\n",
      "Patient: 1\n",
      "Patient: 2\n",
      "Patient: 3\n",
      "Patient: 0\n",
      "Patient: 1\n",
      "Patient: 2\n",
      "Finished\n",
      "1.083162624\n"
     ]
    }
   ],
   "source": [
    "#from my_lib import *\n",
    "from os import listdir\n",
    "import os\n",
    "\n",
    "# Set name of who is running the script to determine which path to use\n",
    "name = \"linus\"\n",
    "\n",
    "# Code snippet to fix that colab notebook and local notebook access data\n",
    "# through different paths\n",
    "var = os.uname()\n",
    "run_on_colab = var[0] == \"Linux\"\n",
    "\n",
    "carl_path = \"/content/my_drive/My Drive/Plugg/\"\n",
    "linus_path = \"/content/my_drive/My Drive/\"\n",
    "\n",
    "if name == \"linus\":\n",
    "  path = linus_path\n",
    "else:\n",
    "  path = carl_path\n",
    "\n",
    "if run_on_colab:\n",
    "    base_path = path + \"EXJOBB/\"\n",
    "else:\n",
    "    base_path = ''\n",
    "\n",
    "# Much cleaner loading of patients\n",
    "train_data = load_patients2(i=0, j=4, base_path=base_path)\n",
    "val_data = load_patients2(i=269, j=272, base_path=base_path)\n",
    "\n",
    "print('Finished')\n",
    "print_memory_use()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SCUKXYxiZPqO"
   },
   "source": [
    "Separate input and labels and validate that the loading of the data has been done correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 322733,
     "status": "ok",
     "timestamp": 1571900573402,
     "user": {
      "displayName": "Linus Lagergren",
      "photoUrl": "",
      "userId": "10069920663213268691"
     },
     "user_tz": -60
    },
    "id": "PidEBsLpNKvT",
    "outputId": "0ec470eb-be35-48c0-b6dc-1ad0999119d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(184, 240, 240, 1)\n",
      "(184, 240, 240, 2)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c2bb8f390>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train = train_data[0]\n",
    "Y_train = train_data[1]\n",
    "\n",
    "X_val = val_data[0]\n",
    "Y_val = val_data[1]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "\n",
    "# This will show a slice of a patient\n",
    "ind = 70\n",
    "patient = X_train[ind, :, :, :]\n",
    "patient_labels = Y_train[ind, :, :]\n",
    "plt.imshow(patient[:,:,0])\n",
    "plt.show()\n",
    "plt.imshow(patient_labels[:,:,0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3705e3NYZ5ln"
   },
   "source": [
    "# New main training cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 322717,
     "status": "ok",
     "timestamp": 1571900573403,
     "user": {
      "displayName": "Linus Lagergren",
      "photoUrl": "",
      "userId": "10069920663213268691"
     },
     "user_tz": -60
    },
    "id": "8JHoeyzwFW9T",
    "outputId": "e17f795a-1cc1-4fd3-b4da-9f45045fbaf8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'weights_path': 'Training_session_0/weights.h5', 'config_path': 'Training_session_0/config.json', 'samples_used': 90, 'keep_training': False, 'history': {'training_samples_used': 0, 'loss': [], 'val_loss': []}}\n"
     ]
    }
   ],
   "source": [
    "# Load config file to session here\n",
    "if run_on_colab:\n",
    "    config_path = path + \"EXJOBB/training_sessions/trainin_tumor_slices_only/config.json\"\n",
    "    weights_path = path + \"EXJOBB/training_sessions/trainin_tumor_slices_only/weights.json\"\n",
    "    config_path = \"/content/my_drive/My Drive/EXJOBB/training_sessions/tumor_slices_with_all_classes/config.json\"\n",
    "else:\n",
    "    config_path = \"config_0.json\"\n",
    "\n",
    "with open(config_path, 'r') as config_file:\n",
    "    config = json.load(config_file)\n",
    "\n",
    "# Reset file to empty loss-values and/or change paths to config and weights\n",
    "weights_path = \"Training_session_0/weights.h5\"\n",
    "config_path = \"Training_session_0/config.json\"\n",
    "reset_config(config, config_path = config_path, weights_path=weights_path)\n",
    "\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 751
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10416089,
     "status": "error",
     "timestamp": 1570728343243,
     "user": {
      "displayName": "Linus Lagergren",
      "photoUrl": "",
      "userId": "10069920663213268691"
     },
     "user_tz": -120
    },
    "id": "oFp9Vq4udUGo",
    "outputId": "e619def7-c222-44d2-cdbf-710499bcd746"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1105 10:36:29.873978 4370068928 deprecation_wrapper.py:119] From /Users/linuslagergren/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1105 10:36:29.890714 4370068928 deprecation_wrapper.py:119] From /Users/linuslagergren/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1105 10:36:29.893912 4370068928 deprecation_wrapper.py:119] From /Users/linuslagergren/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "W1105 10:36:29.919120 4370068928 deprecation_wrapper.py:119] From /Users/linuslagergren/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W1105 10:36:30.021285 4370068928 deprecation_wrapper.py:119] From /Users/linuslagergren/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W1105 10:36:30.029247 4370068928 deprecation.py:506] From /Users/linuslagergren/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W1105 10:36:30.097050 4370068928 deprecation_wrapper.py:119] From /Users/linuslagergren/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2239: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "/Users/linuslagergren/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:625: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"so...)`\n",
      "W1105 10:36:30.305849 4370068928 deprecation_wrapper.py:119] From /Users/linuslagergren/anaconda/lib/python3.6/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1105 10:36:30.313517 4370068928 deprecation_wrapper.py:119] From /Users/linuslagergren/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'softmax_1_target' with dtype float and shape [?,?,?]\n\t [[node softmax_1_target (defined at /Users/linuslagergren/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:541) ]]\n\nOriginal stack trace for 'softmax_1_target':\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 563, in start\n    self.io_loop.start()\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2855, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n    return runner(coro)\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3058, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-16-1cd0f21390fc>\", line 14, in <module>\n    my_unet = unet(input_size = (240, 240, 1), num_classes=2)\n  File \"<ipython-input-9-ac10ede335ff>\", line 626, in unet\n    model.compile(optimizer = Adam(lr=learning_rate), loss = 'categorical_crossentropy', metrics=[dice_coefficient, ful_IoU])\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/site-packages/keras/engine/training.py\", line 241, in compile\n    dtype=K.dtype(self.outputs[i]))\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 541, in placeholder\n    x = tf.placeholder(dtype, shape=shape, name=name)\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 2143, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 6262, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1341\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'softmax_1_target' with dtype float and shape [?,?,?]\n\t [[{{node softmax_1_target}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-1cd0f21390fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Initialize network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mmy_unet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m240\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m240\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'keep_training'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-ac10ede335ff>\u001b[0m in \u001b[0;36munet\u001b[0;34m(pretrained_weights, input_size, num_classes, learning_rate)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdice_coefficient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mful_IoU\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpretrained_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[1;32m    452\u001b[0m                 \u001b[0moutput_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnested_metrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                 \u001b[0moutput_weighted_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnested_weighted_metrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m                 \u001b[0mhandle_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m                 \u001b[0mhandle_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_weighted_metrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mhandle_metrics\u001b[0;34m(metrics, weights)\u001b[0m\n\u001b[1;32m    421\u001b[0m                     metric_result = weighted_metric_fn(y_true, y_pred,\n\u001b[1;32m    422\u001b[0m                                                        \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m                                                        mask=masks[i])\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;31m# Append to self.metrics_names, self.metric_tensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mweighted\u001b[0;34m(y_true, y_pred, weights, mask)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \"\"\"\n\u001b[1;32m    427\u001b[0m         \u001b[0;31m# score_array has ndim >= 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0mscore_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0;31m# Cast the mask to floatX to avoid float64 upcasting in Theano\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-ac10ede335ff>\u001b[0m in \u001b[0;36mful_IoU\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mful_IoU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m     \u001b[0mintersection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m     \u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0my2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    701\u001b[0m     \u001b[0;34m{\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mnp_implementation\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m     \"\"\"\n\u001b[0;32m--> 703\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mto_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m     \"\"\"\n\u001b[0;32m--> 731\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    732\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   5577\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5578\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 5579\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1368\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'softmax_1_target' with dtype float and shape [?,?,?]\n\t [[node softmax_1_target (defined at /Users/linuslagergren/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:541) ]]\n\nOriginal stack trace for 'softmax_1_target':\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 563, in start\n    self.io_loop.start()\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2855, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n    return runner(coro)\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3058, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-16-1cd0f21390fc>\", line 14, in <module>\n    my_unet = unet(input_size = (240, 240, 1), num_classes=2)\n  File \"<ipython-input-9-ac10ede335ff>\", line 626, in unet\n    model.compile(optimizer = Adam(lr=learning_rate), loss = 'categorical_crossentropy', metrics=[dice_coefficient, ful_IoU])\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/site-packages/keras/engine/training.py\", line 241, in compile\n    dtype=K.dtype(self.outputs[i]))\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 541, in placeholder\n    x = tf.placeholder(dtype, shape=shape, name=name)\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 2143, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 6262, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"/Users/linuslagergren/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "# The path to where to save weights and initialize ModelCheckpoint\n",
    "weights_path = config['weights_path']\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "MyModelCheckPoint = ModelCheckpoint(weights_path, verbose=0, save_weights_only=True, period=1)\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "reset_config(config, config_path = config_path, weights_path=weights_path)\n",
    "\n",
    "if config['keep_training'] == True:\n",
    "    # Keep training on the old weights\n",
    "    my_unet = unet(input_size = (240, 240, 1), num_classes=2, pretrained_weights = weights_path)\n",
    "else:\n",
    "    # Initialize network\n",
    "    my_unet = unet(input_size = (240, 240, 1), num_classes=2)\n",
    "    config['keep_training'] = True\n",
    "\n",
    "assert not np.any(np.isnan(X_train)), 'Input contain nans'\n",
    "\n",
    "#Y_train = Y_train.reshape(Y_train.shape[0], -1, 4)\n",
    "validation_data = (X_val, Y_val.reshape(-1,240,240,1))\n",
    "\n",
    "#plt.imshow(my_unet.predict(X_train[60, :, :].reshape(1,240,240,1)).reshape(240,240))\n",
    "\n",
    "# Returns an object with accuracy and loss\n",
    "\n",
    "history = my_unet.fit(x=X_train, \n",
    "                      y=Y_train.reshape(-1,240,240,1), \n",
    "                      batch_size=64,\n",
    "                      epochs=100, \n",
    "                      verbose=1, \n",
    "                      callbacks=[CallbackJSON(config=config), MyModelCheckPoint, es],\n",
    "                      validation_split=0.0, \n",
    "                      validation_data=validation_data, \n",
    "                      shuffle=True, \n",
    "                      class_weight=None, \n",
    "                      sample_weight=None, \n",
    "                      initial_epoch=0, \n",
    "                      steps_per_epoch=None, \n",
    "                      validation_steps=None, \n",
    "                      validation_freq=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qfr5L5aFNKvc"
   },
   "outputs": [],
   "source": [
    "loss = config['history']['loss']\n",
    "val_loss = config['history']['val_loss']\n",
    "plt.plot(loss)\n",
    "plt.show()\n",
    "plt.plot(val_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AEz-JB1iNKve"
   },
   "outputs": [],
   "source": [
    "ind = 10\n",
    "my_unet = unet(input_size = (240, 240, 4), num_classes = 4)\n",
    "my_unet.load_weights(config['weights_path'])\n",
    "\n",
    "yhat = my_unet.predict(val_data[ind, :, :, :].reshape(1, 240, 240, 4))\n",
    "\n",
    "#plot_OHE(yhat.reshape(240, 240, 4))\n",
    "\n",
    "plotable = OHE_uncoding(yhat.reshape(240, 240, 4), mapping)\n",
    "plt.imshow(plotable)\n",
    "plt.show()\n",
    "plt.imshow(val_labels[ind,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6_r-v-APucCd"
   },
   "outputs": [],
   "source": [
    "config['weights_path'] = \"/content/my_drive/My Drive/EXJOBB/training_sessions/100_epochs_10_patients_lr_1e-4/weights.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1eZr43sMNKvf"
   },
   "outputs": [],
   "source": [
    "my_unet = unet(input_size = (240, 240, 4), num_classes = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TOAHUXKPZPqc"
   },
   "outputs": [],
   "source": [
    "#yhat = my_unet.predict(X_train[48].reshape(1,240,240,4))\n",
    "yhat = my_unet.predict(X_train[0:100])\n",
    "#yhat = yhat.reshape(240,240,4)\n",
    "#plot_OHE(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0eaoErIeZPqe"
   },
   "outputs": [],
   "source": [
    "\n",
    "hist = plt.hist(yhat[:,:,0].reshape(-1), bins='auto', log=True)\n",
    "plt.show()\n",
    "hist = plt.hist(yhat[:,:,1].reshape(-1), bins='auto', log=True)\n",
    "plt.show()\n",
    "hist = plt.hist(yhat[:,:,2].reshape(-1), bins='auto', log=True)\n",
    "plt.show()\n",
    "hist = plt.hist(yhat[:,:,3].reshape(-1), bins='auto', log=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7yDcqFWqZPqg"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "segmentation_brats_colab.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
